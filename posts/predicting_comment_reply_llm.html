<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="fr" xml:lang="fr"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.37">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="description" content="Finetuning of Camembert on predicting, using a Le Soleil Facebook post comment as input, whether it will receive a response or not.">

<title>multiverse – Predicting reply under comment with LLM</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/cookie-consent/cookie-consent.js"></script>
<link href="../site_libs/cookie-consent/cookie-consent.css" rel="stylesheet">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "Pas de résultats",
    "search-matching-documents-text": "documents trouvés",
    "search-copy-link-title": "Copier le lien vers la recherche",
    "search-hide-matches-text": "Cacher les correspondances additionnelles",
    "search-more-match-text": "correspondance de plus dans ce document",
    "search-more-matches-text": "correspondances de plus dans ce document",
    "search-clear-button-title": "Effacer",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Annuler",
    "search-submit-button-title": "Envoyer",
    "search-label": "Recherche"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-X5E8KFGB6H"></script>

<script type="text/plain" cookie-consent="tracking">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-X5E8KFGB6H', { 'anonymize_ip': true});
</script>

<script type="text/javascript" charset="UTF-8">
document.addEventListener('DOMContentLoaded', function () {
cookieconsent.run({
  "notice_banner_type":"simple",
  "consent_type":"implied",
  "palette":"light",
  "language":"en",
  "page_load_consent_levels":["strictly-necessary","functionality","tracking","targeting"],
  "notice_banner_reject_button_hide":false,
  "preferences_center_close_button_hide":false,
  "website_name":""
  ,
"language":"fr"
  });
});
</script> 
  
<style>html{ scroll-behavior: smooth; }</style>


<link rel="stylesheet" href="../assets/styles.css">
<meta property="og:title" content="multiverse - Predicting reply under comment with LLM">
<meta property="og:description" content="Finetuning of Camembert on predicting, using a Le Soleil Facebook post comment as input, whether it will receive a response or not.">
<meta property="og:site_name" content="multiverse">
<meta name="twitter:title" content="multiverse - Predicting reply under comment with LLM">
<meta name="twitter:description" content="Finetuning of Camembert on predicting, using a Le Soleil Facebook post comment as input, whether it will receive a response or not.">
<meta name="twitter:creator" content="@amenalahassa">
<meta name="twitter:card" content="summary">
</head>

<body class="nav-sidebar floating slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Basculer la barre latérale" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item">
      multiverse
      </li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Basculer la barre latérale" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Recherche" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">multiverse</a> 
        <div class="sidebar-tools-main">
    <a href="https://www.linkedin.com/in/alkonrad/" title="" class="quarto-navigation-tool px-1" aria-label=""><i class="bi bi-linkedin"></i></a>
  <a href="" class="quarto-reader-toggle quarto-navigation-tool px-1" onclick="window.quartoToggleReader(); return false;" title="Basculer en mode lecteur">
  <div class="quarto-reader-toggle-btn">
  <i class="bi"></i>
  </div>
</a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Recherche"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Blog</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../about.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">L’auteur</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Sur cette page</h2>
   
  <ul>
  <li><a href="#context" id="toc-context" class="nav-link active" data-scroll-target="#context">Context</a></li>
  <li><a href="#dependence" id="toc-dependence" class="nav-link" data-scroll-target="#dependence">Dependence</a></li>
  <li><a href="#about-our-datasets" id="toc-about-our-datasets" class="nav-link" data-scroll-target="#about-our-datasets">About our datasets</a></li>
  <li><a href="#class-and-functions" id="toc-class-and-functions" class="nav-link" data-scroll-target="#class-and-functions">Class and functions</a></li>
  <li><a href="#training" id="toc-training" class="nav-link" data-scroll-target="#training">Training</a>
  <ul class="collapse">
  <li><a href="#evaluations" id="toc-evaluations" class="nav-link" data-scroll-target="#evaluations">Evaluations</a></li>
  <li><a href="#modeling" id="toc-modeling" class="nav-link" data-scroll-target="#modeling">Modeling</a></li>
  <li><a href="#fine-tuning" id="toc-fine-tuning" class="nav-link" data-scroll-target="#fine-tuning">Fine tuning</a></li>
  </ul></li>
  <li><a href="#takeaways" id="toc-takeaways" class="nav-link" data-scroll-target="#takeaways">Takeaways</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/amenalahassa/amenalahassa/issues/new" class="toc-action"><i class="bi bi-github"></i>Faire part d'un problème</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Predicting reply under comment with LLM</h1>
  <div class="quarto-categories">
    <div class="quarto-category">LLM</div>
    <div class="quarto-category">Classification</div>
    <div class="quarto-category">Unbalanced Dataset</div>
  </div>
  </div>

<div>
  <div class="description">
    Finetuning of Camembert on predicting, using a Le Soleil Facebook post comment as input, whether it will receive a response or not.
  </div>
</div>


<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">Date de publication</div>
    <div class="quarto-title-meta-contents">
      <p class="date">21 mai 2024</p>
    </div>
  </div>
  
    <div>
    <div class="quarto-title-meta-heading">Modifié</div>
    <div class="quarto-title-meta-contents">
      <p class="date-modified">30 mai 2024</p>
    </div>
  </div>
    
  </div>
  


</header>


<section id="context" class="level2">
<h2 class="anchored" data-anchor-id="context">Context</h2>
<p>This project originally started as a school assignment for Big Data class. The notebook presented here demonstrates the use of a large language model (LLM) to tackle a binary classification problem. Specifically, our objective is to predict whether a comment will receive a response or not.</p>
<p>To achieve this, we use an enriched dataset compiled from comments on Le Soleil’s Facebook posts. I will also share a separate notebook detailing the process of building this dataset. Additionally, I plan to publish another post explaining how to utilize simple feedforward neural networks or statistical models based on various comment features or the comment text itself.</p>
<p>Let’s dive in!</p>
</section>
<section id="dependence" class="level2">
<h2 class="anchored" data-anchor-id="dependence">Dependence</h2>
<p>I prefer to set aside the cell that install system dependency. It always produces a lot of useless gx3di3ce… You get it, right ?</p>
<div id="cell-4" class="cell" data-execution="{&quot;iopub.status.busy&quot;:&quot;2024-05-16T22:47:58.621291Z&quot;,&quot;iopub.execute_input&quot;:&quot;2024-05-16T22:47:58.621693Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-05-16T22:48:24.158787Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-05-16T22:47:58.621662Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-05-16T22:48:24.157602Z&quot;}" data-trusted="true">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install torchsampler</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install sacremoses</span></code><button title="Copier vers le presse-papier" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>Now, let’s import some packages to have fun !</p>
<div id="cell-6" class="cell" data-execution="{&quot;iopub.status.busy&quot;:&quot;2024-05-16T22:48:24.161082Z&quot;,&quot;iopub.execute_input&quot;:&quot;2024-05-16T22:48:24.161438Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-05-16T22:48:24.487077Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-05-16T22:48:24.161404Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-05-16T22:48:24.486273Z&quot;}" data-trusted="true" data-execution_count="2">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> transformers, torch</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> multiprocessing <span class="im">as</span> mp</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> time</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> AutoModelForSequenceClassification, AutoTokenizer</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> Dataset</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score, precision_score, recall_score, confusion_matrix</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchsampler <span class="im">import</span> ImbalancedDatasetSampler</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm <span class="im">import</span> tqdm</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.optim.lr_scheduler <span class="im">import</span> ReduceLROnPlateau</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> clear_output</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a><span class="co"># warnings.filterwarnings('ignore')</span></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> <span class="st">'cuda'</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">'cpu'</span></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a>mp.cpu_count() <span class="co"># used to set the number of num_worker for Dataloader, usually the half of it </span></span></code><button title="Copier vers le presse-papier" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>And since I use Google colab, I mount my drive to load the datasets later.</p>
<div id="cell-8" class="cell" data-outputid="aac39525-ff34-4217-825e-b73595c599ff" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># only if you are using Google colab of course...</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> google.colab <span class="im">import</span> drive</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>drive.mount(<span class="st">'/content/drive'</span>)</span></code><button title="Copier vers le presse-papier" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Mounted at /content/drive</code></pre>
</div>
</div>
</section>
<section id="about-our-datasets" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="about-our-datasets">About our datasets</h2>
<p>In this section, we will explore the dataset used for our binary classification problem. The dataset has been divided into training and testing sets, with 70% of the data allocated for training and the remaining 30% for testing. This split ensures that we have a robust training set to build our model while retaining a sufficient portion of the data for evaluating the model’s performance.</p>
<p>Let’s load the train and the test sets.</p>
<div id="cell-11" class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>dirpath <span class="op">=</span> <span class="st">'/content/drive/MyDrive/DataSets/big_data/datasets'</span> <span class="co"># specify here the path to the dataset</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>train <span class="op">=</span> pd.read_csv(dirpath <span class="op">+</span> <span class="st">'/split/train_dataset.csv'</span>, index_col<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>test <span class="op">=</span> pd.read_csv(dirpath <span class="op">+</span> <span class="st">'/split/valid_dataset.csv'</span>, index_col<span class="op">=</span><span class="dv">0</span>)</span></code><button title="Copier vers le presse-papier" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>A few statistics about our dataset. First of all, it contains almost a million rows.</p>
<div id="cell-13" class="cell" data-outputid="5e429f03-52cb-4fd3-8666-97f14baf1375" data-execution_count="5">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>dataset <span class="op">=</span> pd.concat([train, test])</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f'Dataset shape: </span><span class="sc">{</span>dataset<span class="sc">.</span>shape<span class="sc">}</span><span class="ss">'</span>)</span></code><button title="Copier vers le presse-papier" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Dataset shape: (935698, 68)</code></pre>
</div>
</div>
<p>Secondly, the dataset is highly unbalanced. The following graph shows that there are only ~13% of comments with replies, by which I mean that these comments have received at least one comment.</p>
<div id="cell-15" class="cell" data-outputid="18b63c43-03e4-4e3b-f0e5-7ed81288739d" data-execution_count="6">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>dataset[<span class="st">'target'</span>].value_counts(normalize<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copier vers le presse-papier" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>target
False    0.876036
True     0.123964
Name: proportion, dtype: float64</code></pre>
</div>
</div>
<div id="cell-fig-cap-margin0" class="cell page-columns page-full" data-outputid="85557c40-d918-45eb-f3f8-813cf72c9a94" data-execution_count="7">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>dataset[<span class="st">'target'</span>].value_counts().plot(kind<span class="op">=</span><span class="st">'bar'</span>)</span></code><button title="Copier vers le presse-papier" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display page-columns page-full">
<div id="fig-cap-margin0" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-cap-margin0-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="predicting_comment_reply_llm_files/figure-html/fig-cap-margin0-output-1.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-cap-margin0-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;1: Barchart of the count of each class
</figcaption>
</figure>
</div>
</div>
</div>
<p>We have then two significant issues. Firstly, running the training on the entire dataset would be extremely time-consuming, even with substantial computational resources. Secondly, our dataset is unbalanced, which presents a challenge for accurate model training.</p>
<p>To address these issues, I opted for undersampling, ensuring an equal number of items from each class. This approach allows us to run our experiments more efficiently and mitigates the problem of data imbalance. Later in the notebook, we will explore the impact of the amount of data used on the model’s performance.</p>
</section>
<section id="class-and-functions" class="level2">
<h2 class="anchored" data-anchor-id="class-and-functions">Class and functions</h2>
<p>I write the CommentDataset class as a custom dataset designed for handling text data. It inherits from the Dataset class provided by PyTorch. This class is specifically tailored for tokenizing and preparing text data along with their corresponding labels for use in a model.</p>
<div id="cell-20" class="cell" data-execution="{&quot;iopub.status.busy&quot;:&quot;2024-05-16T22:48:47.461504Z&quot;,&quot;iopub.execute_input&quot;:&quot;2024-05-16T22:48:47.461808Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-05-16T22:48:47.470522Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-05-16T22:48:47.461784Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-05-16T22:48:47.469657Z&quot;}" data-trusted="true" data-execution_count="8">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> CommentDataset(Dataset):</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, message, labels, tokenizer):</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.message <span class="op">=</span> message</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.labels <span class="op">=</span> labels</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.tokenizer <span class="op">=</span> tokenizer</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> get_labels(<span class="va">self</span>):</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.labels</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__len__</span>(<span class="va">self</span>):</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="bu">len</span>(<span class="va">self</span>.message)</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__getitem__</span>(<span class="va">self</span>, idx):</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>        text <span class="op">=</span> <span class="va">self</span>.message[idx]</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>        label <span class="op">=</span> <span class="va">self</span>.labels[idx]</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a>        inputs <span class="op">=</span> <span class="va">self</span>.tokenizer.encode_plus(text, <span class="va">None</span>, add_special_tokens<span class="op">=</span><span class="va">True</span>, padding<span class="op">=</span><span class="st">'max_length'</span>, return_token_type_ids<span class="op">=</span><span class="va">True</span>, truncation<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> {</span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a>            <span class="st">'input_ids'</span>: torch.tensor(inputs[<span class="st">'input_ids'</span>], dtype<span class="op">=</span>torch.<span class="bu">long</span>),</span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a>            <span class="st">'attention_mask'</span>: torch.tensor(inputs[<span class="st">'attention_mask'</span>], dtype<span class="op">=</span>torch.<span class="bu">long</span>),</span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>            <span class="st">'token_type_ids'</span>: torch.tensor(inputs[<span class="st">"token_type_ids"</span>], dtype<span class="op">=</span>torch.<span class="bu">long</span>),</span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a>            <span class="st">'labels'</span>: torch.tensor(label, dtype<span class="op">=</span>torch.<span class="bu">float</span>)</span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a>        }</span></code><button title="Copier vers le presse-papier" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>The <code>train_model</code> method is designed to train a machine learning model using a provided training and testing dataloader, while tracking various performance metrics such as loss, accuracy, precision, recall, and a custom F2 score across multiple epochs, and implementing early stopping based on validation performance. The <code>test_model</code> method evaluates the trained model on a validation dataset, computing and printing evaluation metrics to assess the model’s performance.</p>
<div id="cell-22" class="cell" data-execution="{&quot;iopub.status.busy&quot;:&quot;2024-05-16T22:48:47.471853Z&quot;,&quot;iopub.execute_input&quot;:&quot;2024-05-16T22:48:47.472149Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-05-16T22:48:47.496708Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-05-16T22:48:47.472105Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-05-16T22:48:47.495859Z&quot;}" data-trusted="true" data-execution_count="19">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> train_model(model, train_dataloader, test_dataloader, history<span class="op">=</span>{}, num_epochs<span class="op">=</span><span class="dv">5</span>, lr<span class="op">=</span><span class="fl">5e-5</span>, early_stopping_patience<span class="op">=</span><span class="dv">3</span>, weight_decay<span class="op">=</span><span class="fl">0.01</span>):</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>    device <span class="op">=</span> torch.device(<span class="st">"cuda"</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">"cpu"</span>)</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>    model.to(device)</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>    optimizer <span class="op">=</span> torch.optim.AdamW(model.parameters(), lr<span class="op">=</span>lr, weight_decay<span class="op">=</span>weight_decay)</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>    scheduler <span class="op">=</span> ReduceLROnPlateau(optimizer, mode<span class="op">=</span><span class="st">'max'</span>, factor<span class="op">=</span><span class="fl">0.1</span>, patience<span class="op">=</span><span class="dv">1</span>)  <span class="co"># ReduceLROnPlateau scheduler</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>    loss_fn <span class="op">=</span> torch.nn.BCEWithLogitsLoss()  <span class="co"># Binary Cross-Entropy Loss</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>    history[<span class="st">'train_loss'</span>] <span class="op">=</span> []</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>    history[<span class="st">'train_accuracy'</span>] <span class="op">=</span> []</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>    history[<span class="st">'train_precision'</span>] <span class="op">=</span> []</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>    history[<span class="st">'train_recall'</span>] <span class="op">=</span> []</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>    history[<span class="st">'test_accuracy'</span>] <span class="op">=</span> []</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>    history[<span class="st">'test_precision'</span>] <span class="op">=</span> []</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>    history[<span class="st">'test_recall'</span>] <span class="op">=</span> []</span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>    history[<span class="st">'epochs'</span>] <span class="op">=</span> []</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>    history[<span class="st">'test_loss'</span>] <span class="op">=</span> []</span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>    history[<span class="st">'valid_score'</span>] <span class="op">=</span> []</span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>    best_valid_score <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>    early_stopping_counter <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(num_epochs):</span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a>        model.train()</span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a>        train_loss <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a>        train_preds <span class="op">=</span> []</span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a>        train_labels <span class="op">=</span> []</span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Training loop</span></span>
<span id="cb12-28"><a href="#cb12-28" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> _, batch <span class="kw">in</span> <span class="bu">enumerate</span>(tqdm(train_dataloader, desc<span class="op">=</span><span class="ss">f'Epoch </span><span class="sc">{</span>epoch <span class="op">+</span> <span class="dv">1</span><span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>num_epochs<span class="sc">}</span><span class="ss">'</span>)):</span>
<span id="cb12-29"><a href="#cb12-29" aria-hidden="true" tabindex="-1"></a>            optimizer.zero_grad()</span>
<span id="cb12-30"><a href="#cb12-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-31"><a href="#cb12-31" aria-hidden="true" tabindex="-1"></a>            input_ids <span class="op">=</span> batch[<span class="st">'input_ids'</span>].to(device)</span>
<span id="cb12-32"><a href="#cb12-32" aria-hidden="true" tabindex="-1"></a>            attention_mask <span class="op">=</span> batch[<span class="st">'attention_mask'</span>].to(device)</span>
<span id="cb12-33"><a href="#cb12-33" aria-hidden="true" tabindex="-1"></a>            token_type_ids <span class="op">=</span> batch[<span class="st">'token_type_ids'</span>].to(device)</span>
<span id="cb12-34"><a href="#cb12-34" aria-hidden="true" tabindex="-1"></a>            labels <span class="op">=</span> batch[<span class="st">'labels'</span>].to(device)</span>
<span id="cb12-35"><a href="#cb12-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-36"><a href="#cb12-36" aria-hidden="true" tabindex="-1"></a>            outputs <span class="op">=</span> model(input_ids, attention_mask<span class="op">=</span>attention_mask, token_type_ids<span class="op">=</span>token_type_ids)</span>
<span id="cb12-37"><a href="#cb12-37" aria-hidden="true" tabindex="-1"></a>            logits <span class="op">=</span> outputs.logits.squeeze(<span class="dv">1</span>)</span>
<span id="cb12-38"><a href="#cb12-38" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> loss_fn(logits, labels)</span>
<span id="cb12-39"><a href="#cb12-39" aria-hidden="true" tabindex="-1"></a>            loss.backward()</span>
<span id="cb12-40"><a href="#cb12-40" aria-hidden="true" tabindex="-1"></a>            optimizer.step()</span>
<span id="cb12-41"><a href="#cb12-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-42"><a href="#cb12-42" aria-hidden="true" tabindex="-1"></a>            train_loss <span class="op">+=</span> loss.item()</span>
<span id="cb12-43"><a href="#cb12-43" aria-hidden="true" tabindex="-1"></a>            train_preds.extend((logits <span class="op">&gt;</span> <span class="fl">0.5</span>).<span class="bu">int</span>().tolist())</span>
<span id="cb12-44"><a href="#cb12-44" aria-hidden="true" tabindex="-1"></a>            train_labels.extend(labels.tolist())</span>
<span id="cb12-45"><a href="#cb12-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-46"><a href="#cb12-46" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Calculate metrics on training set</span></span>
<span id="cb12-47"><a href="#cb12-47" aria-hidden="true" tabindex="-1"></a>        train_accuracy <span class="op">=</span> accuracy_score(train_labels, train_preds)</span>
<span id="cb12-48"><a href="#cb12-48" aria-hidden="true" tabindex="-1"></a>        train_precision <span class="op">=</span> precision_score(train_labels, train_preds, average<span class="op">=</span><span class="st">'binary'</span>)</span>
<span id="cb12-49"><a href="#cb12-49" aria-hidden="true" tabindex="-1"></a>        train_recall <span class="op">=</span> recall_score(train_labels, train_preds, average<span class="op">=</span><span class="st">'binary'</span>)</span>
<span id="cb12-50"><a href="#cb12-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-51"><a href="#cb12-51" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Evaluation loop</span></span>
<span id="cb12-52"><a href="#cb12-52" aria-hidden="true" tabindex="-1"></a>        model.<span class="bu">eval</span>()</span>
<span id="cb12-53"><a href="#cb12-53" aria-hidden="true" tabindex="-1"></a>        test_preds <span class="op">=</span> []</span>
<span id="cb12-54"><a href="#cb12-54" aria-hidden="true" tabindex="-1"></a>        test_labels <span class="op">=</span> []</span>
<span id="cb12-55"><a href="#cb12-55" aria-hidden="true" tabindex="-1"></a>        test_loss <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb12-56"><a href="#cb12-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-57"><a href="#cb12-57" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> torch.no_grad():</span>
<span id="cb12-58"><a href="#cb12-58" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> batch <span class="kw">in</span> test_dataloader:</span>
<span id="cb12-59"><a href="#cb12-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-60"><a href="#cb12-60" aria-hidden="true" tabindex="-1"></a>                input_ids <span class="op">=</span> batch[<span class="st">'input_ids'</span>].to(device)</span>
<span id="cb12-61"><a href="#cb12-61" aria-hidden="true" tabindex="-1"></a>                attention_mask <span class="op">=</span> batch[<span class="st">'attention_mask'</span>].to(device)</span>
<span id="cb12-62"><a href="#cb12-62" aria-hidden="true" tabindex="-1"></a>                token_type_ids <span class="op">=</span> batch[<span class="st">'token_type_ids'</span>].to(device)</span>
<span id="cb12-63"><a href="#cb12-63" aria-hidden="true" tabindex="-1"></a>                labels <span class="op">=</span> batch[<span class="st">'labels'</span>].to(device)</span>
<span id="cb12-64"><a href="#cb12-64" aria-hidden="true" tabindex="-1"></a>                outputs <span class="op">=</span> model(input_ids, attention_mask<span class="op">=</span>attention_mask, token_type_ids<span class="op">=</span>token_type_ids)</span>
<span id="cb12-65"><a href="#cb12-65" aria-hidden="true" tabindex="-1"></a>                logits <span class="op">=</span> outputs.logits.squeeze(<span class="dv">1</span>)</span>
<span id="cb12-66"><a href="#cb12-66" aria-hidden="true" tabindex="-1"></a>                loss <span class="op">=</span> loss_fn(logits, labels)</span>
<span id="cb12-67"><a href="#cb12-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-68"><a href="#cb12-68" aria-hidden="true" tabindex="-1"></a>                test_loss <span class="op">+=</span> loss.item()</span>
<span id="cb12-69"><a href="#cb12-69" aria-hidden="true" tabindex="-1"></a>                test_preds.extend((logits <span class="op">&gt;</span> <span class="fl">0.5</span>).<span class="bu">int</span>().tolist())</span>
<span id="cb12-70"><a href="#cb12-70" aria-hidden="true" tabindex="-1"></a>                test_labels.extend(labels.tolist())</span>
<span id="cb12-71"><a href="#cb12-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-72"><a href="#cb12-72" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Calculate metrics on test set</span></span>
<span id="cb12-73"><a href="#cb12-73" aria-hidden="true" tabindex="-1"></a>        test_accuracy <span class="op">=</span> accuracy_score(test_labels, test_preds)</span>
<span id="cb12-74"><a href="#cb12-74" aria-hidden="true" tabindex="-1"></a>        test_precision <span class="op">=</span> precision_score(test_labels, test_preds, average<span class="op">=</span><span class="st">'binary'</span>)</span>
<span id="cb12-75"><a href="#cb12-75" aria-hidden="true" tabindex="-1"></a>        test_recall <span class="op">=</span> recall_score(test_labels, test_preds, average<span class="op">=</span><span class="st">'binary'</span>)</span>
<span id="cb12-76"><a href="#cb12-76" aria-hidden="true" tabindex="-1"></a>        tn, fp, fn, tp <span class="op">=</span> confusion_matrix(test_labels, test_preds).ravel()</span>
<span id="cb12-77"><a href="#cb12-77" aria-hidden="true" tabindex="-1"></a>        valid_score <span class="op">=</span> (tp <span class="op">/</span> (tp <span class="op">+</span> fp <span class="op">+</span> fn)) <span class="op">*</span> <span class="dv">100</span></span>
<span id="cb12-78"><a href="#cb12-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-79"><a href="#cb12-79" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Update learning rate scheduler</span></span>
<span id="cb12-80"><a href="#cb12-80" aria-hidden="true" tabindex="-1"></a>        scheduler.step(valid_score)</span>
<span id="cb12-81"><a href="#cb12-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-82"><a href="#cb12-82" aria-hidden="true" tabindex="-1"></a>        history[<span class="st">'epochs'</span>].append(epoch <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb12-83"><a href="#cb12-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-84"><a href="#cb12-84" aria-hidden="true" tabindex="-1"></a>        history[<span class="st">'train_loss'</span>].append(train_loss <span class="op">/</span> <span class="bu">len</span>(train_dataloader))</span>
<span id="cb12-85"><a href="#cb12-85" aria-hidden="true" tabindex="-1"></a>        history[<span class="st">'train_accuracy'</span>].append(train_accuracy)</span>
<span id="cb12-86"><a href="#cb12-86" aria-hidden="true" tabindex="-1"></a>        history[<span class="st">'train_precision'</span>].append(train_precision)</span>
<span id="cb12-87"><a href="#cb12-87" aria-hidden="true" tabindex="-1"></a>        history[<span class="st">'train_recall'</span>].append(train_recall)</span>
<span id="cb12-88"><a href="#cb12-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-89"><a href="#cb12-89" aria-hidden="true" tabindex="-1"></a>        history[<span class="st">'test_loss'</span>].append(test_loss <span class="op">/</span> <span class="bu">len</span>(test_dataloader))</span>
<span id="cb12-90"><a href="#cb12-90" aria-hidden="true" tabindex="-1"></a>        history[<span class="st">'test_accuracy'</span>].append(test_accuracy)</span>
<span id="cb12-91"><a href="#cb12-91" aria-hidden="true" tabindex="-1"></a>        history[<span class="st">'test_precision'</span>].append(test_precision)</span>
<span id="cb12-92"><a href="#cb12-92" aria-hidden="true" tabindex="-1"></a>        history[<span class="st">'test_recall'</span>].append(test_recall)</span>
<span id="cb12-93"><a href="#cb12-93" aria-hidden="true" tabindex="-1"></a>        history[<span class="st">'valid_score'</span>].append(valid_score)</span>
<span id="cb12-94"><a href="#cb12-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-95"><a href="#cb12-95" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Epoch </span><span class="sc">{</span>epoch <span class="op">+</span> <span class="dv">1</span><span class="sc">}</span><span class="ss">/</span><span class="sc">{</span>num_epochs<span class="sc">}</span><span class="ss">:"</span>)</span>
<span id="cb12-96"><a href="#cb12-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-97"><a href="#cb12-97" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  Train Loss: </span><span class="sc">{</span>train_loss <span class="op">/</span> <span class="bu">len</span>(train_dataloader)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb12-98"><a href="#cb12-98" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  Test Loss: </span><span class="sc">{</span>test_loss <span class="op">/</span> <span class="bu">len</span>(test_dataloader)<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb12-99"><a href="#cb12-99" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  Train Accuracy: </span><span class="sc">{</span>train_accuracy<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb12-100"><a href="#cb12-100" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  Train Precision: </span><span class="sc">{</span>train_precision<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb12-101"><a href="#cb12-101" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  Train Recall: </span><span class="sc">{</span>train_recall<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb12-102"><a href="#cb12-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-103"><a href="#cb12-103" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  Test Accuracy: </span><span class="sc">{</span>test_accuracy<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb12-104"><a href="#cb12-104" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  Test Precision: </span><span class="sc">{</span>test_precision<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb12-105"><a href="#cb12-105" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  Test Recall: </span><span class="sc">{</span>test_recall<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb12-106"><a href="#cb12-106" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"  Test F2: </span><span class="sc">{</span>valid_score<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb12-107"><a href="#cb12-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-108"><a href="#cb12-108" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Early stopping</span></span>
<span id="cb12-109"><a href="#cb12-109" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> valid_score <span class="op">&gt;</span> best_valid_score:</span>
<span id="cb12-110"><a href="#cb12-110" aria-hidden="true" tabindex="-1"></a>            best_valid_score <span class="op">=</span> valid_score</span>
<span id="cb12-111"><a href="#cb12-111" aria-hidden="true" tabindex="-1"></a>            early_stopping_counter <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb12-112"><a href="#cb12-112" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb12-113"><a href="#cb12-113" aria-hidden="true" tabindex="-1"></a>            early_stopping_counter <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb12-114"><a href="#cb12-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-115"><a href="#cb12-115" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> early_stopping_counter <span class="op">&gt;=</span> early_stopping_patience:</span>
<span id="cb12-116"><a href="#cb12-116" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">"Early stopping triggered!"</span>)</span>
<span id="cb12-117"><a href="#cb12-117" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span></span>
<span id="cb12-118"><a href="#cb12-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-119"><a href="#cb12-119" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> test_model(tokz, model, valid_data, history, device, bs <span class="op">=</span> <span class="dv">16</span>):</span>
<span id="cb12-120"><a href="#cb12-120" aria-hidden="true" tabindex="-1"></a>    model.<span class="bu">eval</span>()</span>
<span id="cb12-121"><a href="#cb12-121" aria-hidden="true" tabindex="-1"></a>    test_preds <span class="op">=</span> []</span>
<span id="cb12-122"><a href="#cb12-122" aria-hidden="true" tabindex="-1"></a>    test_labels <span class="op">=</span> []</span>
<span id="cb12-123"><a href="#cb12-123" aria-hidden="true" tabindex="-1"></a>    test_loss <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb12-124"><a href="#cb12-124" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-125"><a href="#cb12-125" aria-hidden="true" tabindex="-1"></a>    valid_dataset <span class="op">=</span> CommentDataset(valid_data[<span class="dv">0</span>].to_numpy(), valid_data[<span class="dv">1</span>].astype(<span class="bu">int</span>).to_numpy(), tokz)</span>
<span id="cb12-126"><a href="#cb12-126" aria-hidden="true" tabindex="-1"></a>    test_dataloader <span class="op">=</span> torch.utils.data.DataLoader(valid_dataset, batch_size<span class="op">=</span>bs, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb12-127"><a href="#cb12-127" aria-hidden="true" tabindex="-1"></a>    loss_fn <span class="op">=</span> torch.nn.BCEWithLogitsLoss()  <span class="co"># Binary Cross-Entropy Loss</span></span>
<span id="cb12-128"><a href="#cb12-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-129"><a href="#cb12-129" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> torch.no_grad():</span>
<span id="cb12-130"><a href="#cb12-130" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> batch <span class="kw">in</span> test_dataloader:</span>
<span id="cb12-131"><a href="#cb12-131" aria-hidden="true" tabindex="-1"></a>            input_ids <span class="op">=</span> batch[<span class="st">'input_ids'</span>].to(device)</span>
<span id="cb12-132"><a href="#cb12-132" aria-hidden="true" tabindex="-1"></a>            attention_mask <span class="op">=</span> batch[<span class="st">'attention_mask'</span>].to(device)</span>
<span id="cb12-133"><a href="#cb12-133" aria-hidden="true" tabindex="-1"></a>            token_type_ids <span class="op">=</span> batch[<span class="st">'token_type_ids'</span>].to(device)</span>
<span id="cb12-134"><a href="#cb12-134" aria-hidden="true" tabindex="-1"></a>            labels <span class="op">=</span> batch[<span class="st">'labels'</span>].to(device)</span>
<span id="cb12-135"><a href="#cb12-135" aria-hidden="true" tabindex="-1"></a>            outputs <span class="op">=</span> model(input_ids, attention_mask<span class="op">=</span>attention_mask, token_type_ids<span class="op">=</span>token_type_ids)</span>
<span id="cb12-136"><a href="#cb12-136" aria-hidden="true" tabindex="-1"></a>            logits <span class="op">=</span> outputs.logits.squeeze(<span class="dv">1</span>)</span>
<span id="cb12-137"><a href="#cb12-137" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> loss_fn(logits, labels)</span>
<span id="cb12-138"><a href="#cb12-138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-139"><a href="#cb12-139" aria-hidden="true" tabindex="-1"></a>            test_loss <span class="op">+=</span> loss.item()</span>
<span id="cb12-140"><a href="#cb12-140" aria-hidden="true" tabindex="-1"></a>            test_preds.extend((logits <span class="op">&gt;</span> <span class="fl">0.5</span>).<span class="bu">int</span>().tolist())</span>
<span id="cb12-141"><a href="#cb12-141" aria-hidden="true" tabindex="-1"></a>            test_labels.extend(labels.tolist())</span>
<span id="cb12-142"><a href="#cb12-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-143"><a href="#cb12-143" aria-hidden="true" tabindex="-1"></a>    test_accuracy <span class="op">=</span> accuracy_score(test_labels, test_preds)</span>
<span id="cb12-144"><a href="#cb12-144" aria-hidden="true" tabindex="-1"></a>    test_precision <span class="op">=</span> precision_score(test_labels, test_preds)</span>
<span id="cb12-145"><a href="#cb12-145" aria-hidden="true" tabindex="-1"></a>    test_recall <span class="op">=</span> recall_score(test_labels, test_preds)</span>
<span id="cb12-146"><a href="#cb12-146" aria-hidden="true" tabindex="-1"></a>    tn, fp, fn, tp <span class="op">=</span> confusion_matrix(test_labels, test_preds).ravel()</span>
<span id="cb12-147"><a href="#cb12-147" aria-hidden="true" tabindex="-1"></a>    history[<span class="st">'valid_score'</span>] <span class="op">=</span> (tp <span class="op">/</span> (tp <span class="op">+</span> fp <span class="op">+</span> fn)) <span class="op">*</span> <span class="dv">100</span></span>
<span id="cb12-148"><a href="#cb12-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-149"><a href="#cb12-149" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Test Metrics:"</span>)</span>
<span id="cb12-150"><a href="#cb12-150" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Eval Accuracy: </span><span class="sc">{</span>test_accuracy<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb12-151"><a href="#cb12-151" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Eval Precision: </span><span class="sc">{</span>test_precision<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb12-152"><a href="#cb12-152" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Eval Recall: </span><span class="sc">{</span>test_recall<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb12-153"><a href="#cb12-153" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"  Eval F2: </span><span class="sc">{</span>history[<span class="st">'valid_score'</span>]<span class="sc">}</span><span class="ss">"</span>)</span></code><button title="Copier vers le presse-papier" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<p>The <code>plot_history</code> method visualizes the training and testing metrics (loss, accuracy, precision, recall, and F2 score) over epochs using matplotlib. The <code>evaluate_model</code> function assesses the model by optionally plotting the training history and running the <code>test_model</code> function for evaluation metrics. The <code>get_loader</code> function prepares the data loaders for training and testing datasets, including optional under-sampling, and sets up the tokenizer and model for sequence classification tasks. The <code>equal_class_sampling</code> method ensures balanced class distribution by sampling an equal number of instances from each class in the dataset.</p>
<div id="cell-24" class="cell" data-execution="{&quot;iopub.status.busy&quot;:&quot;2024-05-17T00:15:24.440839Z&quot;,&quot;iopub.execute_input&quot;:&quot;2024-05-17T00:15:24.441301Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-05-17T00:15:24.453534Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-05-17T00:15:24.441258Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-05-17T00:15:24.452391Z&quot;}" data-trusted="true" data-execution_count="13">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_history(history):</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">17</span>, <span class="dv">6</span>))</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>    epochs <span class="op">=</span> history[<span class="st">'epochs'</span>]</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>    train_losses <span class="op">=</span> history[<span class="st">'train_loss'</span>]</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>    test_loss <span class="op">=</span> history[<span class="st">'test_loss'</span>]</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>    train_accuracies <span class="op">=</span> history[<span class="st">'train_accuracy'</span>]</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>    test_accuracies <span class="op">=</span> history[<span class="st">'test_accuracy'</span>]</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>    train_precisions <span class="op">=</span> history[<span class="st">'train_precision'</span>]</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>    test_precisions <span class="op">=</span> history[<span class="st">'test_precision'</span>]</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>    train_recall <span class="op">=</span> history[<span class="st">'train_recall'</span>]</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>    test_recall <span class="op">=</span> history[<span class="st">'test_recall'</span>]</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>    valid_score <span class="op">=</span> history[<span class="st">'valid_score'</span>]</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">1</span>)</span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>    plt.plot(epochs, train_losses, label<span class="op">=</span><span class="st">'Training Loss'</span>)</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>    plt.plot(epochs, test_loss, label<span class="op">=</span><span class="st">'Test Loss'</span>)</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">'Epochs'</span>)</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">'Loss'</span>)</span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'Training Loss'</span>)</span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">2</span>)</span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a>    plt.plot(epochs, train_accuracies, label<span class="op">=</span><span class="st">'Training Accuracy'</span>)</span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a>    plt.plot(epochs, test_accuracies, label<span class="op">=</span><span class="st">'Test Accuracy'</span>)</span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">'Epochs'</span>)</span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">'Accuracy'</span>)</span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'Accuracy'</span>)</span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a>    plt.legend()</span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-30"><a href="#cb13-30" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">3</span>)</span>
<span id="cb13-31"><a href="#cb13-31" aria-hidden="true" tabindex="-1"></a>    plt.plot(epochs, train_precisions, label<span class="op">=</span><span class="st">'Training Precision'</span>)</span>
<span id="cb13-32"><a href="#cb13-32" aria-hidden="true" tabindex="-1"></a>    plt.plot(epochs, test_precisions, label<span class="op">=</span><span class="st">'Test Precision'</span>)</span>
<span id="cb13-33"><a href="#cb13-33" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">'Epochs'</span>)</span>
<span id="cb13-34"><a href="#cb13-34" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">'Precision'</span>)</span>
<span id="cb13-35"><a href="#cb13-35" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'Precision'</span>)</span>
<span id="cb13-36"><a href="#cb13-36" aria-hidden="true" tabindex="-1"></a>    plt.legend()</span>
<span id="cb13-37"><a href="#cb13-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-38"><a href="#cb13-38" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">4</span>)</span>
<span id="cb13-39"><a href="#cb13-39" aria-hidden="true" tabindex="-1"></a>    plt.plot(epochs, train_recall, label<span class="op">=</span><span class="st">'Training Recall'</span>)</span>
<span id="cb13-40"><a href="#cb13-40" aria-hidden="true" tabindex="-1"></a>    plt.plot(epochs, test_recall, label<span class="op">=</span><span class="st">'Test Recall'</span>)</span>
<span id="cb13-41"><a href="#cb13-41" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">'Epochs'</span>)</span>
<span id="cb13-42"><a href="#cb13-42" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">'Recall'</span>)</span>
<span id="cb13-43"><a href="#cb13-43" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'Recall'</span>)</span>
<span id="cb13-44"><a href="#cb13-44" aria-hidden="true" tabindex="-1"></a>    plt.legend()</span>
<span id="cb13-45"><a href="#cb13-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-46"><a href="#cb13-46" aria-hidden="true" tabindex="-1"></a>    plt.subplot(<span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">5</span>)</span>
<span id="cb13-47"><a href="#cb13-47" aria-hidden="true" tabindex="-1"></a>    plt.plot(epochs, valid_score, label<span class="op">=</span><span class="st">'Training F2'</span>)</span>
<span id="cb13-48"><a href="#cb13-48" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">'Epochs'</span>)</span>
<span id="cb13-49"><a href="#cb13-49" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">'F2'</span>)</span>
<span id="cb13-50"><a href="#cb13-50" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'F2'</span>)</span>
<span id="cb13-51"><a href="#cb13-51" aria-hidden="true" tabindex="-1"></a>    plt.legend()</span>
<span id="cb13-52"><a href="#cb13-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-53"><a href="#cb13-53" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb13-54"><a href="#cb13-54" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb13-55"><a href="#cb13-55" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-56"><a href="#cb13-56" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> evaluate_model(tokz, model, valid_data, history, device, bs <span class="op">=</span> <span class="dv">16</span>, plot_train<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb13-57"><a href="#cb13-57" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> plot_train:</span>
<span id="cb13-58"><a href="#cb13-58" aria-hidden="true" tabindex="-1"></a>        plot_history(history)</span>
<span id="cb13-59"><a href="#cb13-59" aria-hidden="true" tabindex="-1"></a>    test_model(tokz, model, valid_data, history, device, bs <span class="op">=</span> bs)</span>
<span id="cb13-60"><a href="#cb13-60" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb13-61"><a href="#cb13-61" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_loader(model_nm, dataset, bs <span class="op">=</span> <span class="dv">100</span>, under_sample<span class="op">=</span><span class="va">True</span>, num_class <span class="op">=</span> <span class="dv">1</span>, use_pad_token<span class="op">=</span><span class="va">True</span>, use_special_pad_token<span class="op">=</span><span class="va">False</span>, num_workers<span class="op">=</span><span class="dv">2</span>):</span>
<span id="cb13-62"><a href="#cb13-62" aria-hidden="true" tabindex="-1"></a>    X_train, y_train, X_test, y_test <span class="op">=</span> dataset[<span class="st">'X_train'</span>], dataset[<span class="st">'y_train'</span>], dataset[<span class="st">'X_test'</span>], dataset[<span class="st">'y_test'</span>]</span>
<span id="cb13-63"><a href="#cb13-63" aria-hidden="true" tabindex="-1"></a>    tokz <span class="op">=</span> AutoTokenizer.from_pretrained(model_nm)</span>
<span id="cb13-64"><a href="#cb13-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-65"><a href="#cb13-65" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> AutoModelForSequenceClassification.from_pretrained(model_nm, num_labels <span class="op">=</span> num_class)</span>
<span id="cb13-66"><a href="#cb13-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-67"><a href="#cb13-67" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">len</span>(X_train) <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb13-68"><a href="#cb13-68" aria-hidden="true" tabindex="-1"></a>      <span class="cf">return</span> model, tokz, <span class="va">None</span>, <span class="va">None</span></span>
<span id="cb13-69"><a href="#cb13-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-70"><a href="#cb13-70" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> use_pad_token:</span>
<span id="cb13-71"><a href="#cb13-71" aria-hidden="true" tabindex="-1"></a>        tokz.pad_token <span class="op">=</span> tokz.eos_token</span>
<span id="cb13-72"><a href="#cb13-72" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> use_special_pad_token:</span>
<span id="cb13-73"><a href="#cb13-73" aria-hidden="true" tabindex="-1"></a>        tokz.add_special_tokens({<span class="st">'pad_token'</span>: <span class="st">'[PAD]'</span>})</span>
<span id="cb13-74"><a href="#cb13-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-75"><a href="#cb13-75" aria-hidden="true" tabindex="-1"></a>    model.resize_token_embeddings(<span class="bu">len</span>(tokz))</span>
<span id="cb13-76"><a href="#cb13-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-77"><a href="#cb13-77" aria-hidden="true" tabindex="-1"></a>    train_dataset <span class="op">=</span> CommentDataset(X_train.to_numpy(), y_train.astype(<span class="bu">int</span>).to_numpy(), tokz)</span>
<span id="cb13-78"><a href="#cb13-78" aria-hidden="true" tabindex="-1"></a>    test_dataset <span class="op">=</span> CommentDataset(X_test.to_numpy(), y_test.astype(<span class="bu">int</span>).to_numpy(), tokz)</span>
<span id="cb13-79"><a href="#cb13-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-80"><a href="#cb13-80" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> under_sample:</span>
<span id="cb13-81"><a href="#cb13-81" aria-hidden="true" tabindex="-1"></a>        train_loader <span class="op">=</span> torch.utils.data.DataLoader(train_dataset, sampler<span class="op">=</span>ImbalancedDatasetSampler(train_dataset), batch_size<span class="op">=</span>bs, num_workers<span class="op">=</span>num_workers, pin_memory<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb13-82"><a href="#cb13-82" aria-hidden="true" tabindex="-1"></a>        test_loader <span class="op">=</span> torch.utils.data.DataLoader(test_dataset, shuffle<span class="op">=</span><span class="va">True</span>, batch_size<span class="op">=</span>bs, num_workers<span class="op">=</span>num_workers, pin_memory<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb13-83"><a href="#cb13-83" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb13-84"><a href="#cb13-84" aria-hidden="true" tabindex="-1"></a>        train_loader <span class="op">=</span> torch.utils.data.DataLoader(train_dataset, batch_size<span class="op">=</span>bs, shuffle<span class="op">=</span><span class="va">True</span>, num_workers<span class="op">=</span>num_workers, pin_memory<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb13-85"><a href="#cb13-85" aria-hidden="true" tabindex="-1"></a>        test_loader <span class="op">=</span> torch.utils.data.DataLoader(test_dataset, batch_size<span class="op">=</span>bs, shuffle<span class="op">=</span><span class="va">True</span>, num_workers<span class="op">=</span>num_workers, pin_memory<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb13-86"><a href="#cb13-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-87"><a href="#cb13-87" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> model, tokz, train_loader, test_loader</span>
<span id="cb13-88"><a href="#cb13-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-89"><a href="#cb13-89" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> equal_class_sampling(input_features, target_labels, num_samples):</span>
<span id="cb13-90"><a href="#cb13-90" aria-hidden="true" tabindex="-1"></a>    num_classes <span class="op">=</span> <span class="bu">len</span>(target_labels.unique())</span>
<span id="cb13-91"><a href="#cb13-91" aria-hidden="true" tabindex="-1"></a>    num_samples_per_class <span class="op">=</span> num_samples <span class="op">//</span> num_classes</span>
<span id="cb13-92"><a href="#cb13-92" aria-hidden="true" tabindex="-1"></a>    dataset <span class="op">=</span> pd.DataFrame({<span class="st">'input'</span>: input_features, <span class="st">'target'</span>: target_labels})</span>
<span id="cb13-93"><a href="#cb13-93" aria-hidden="true" tabindex="-1"></a>    grouped <span class="op">=</span> dataset.groupby([<span class="st">'target'</span>])</span>
<span id="cb13-94"><a href="#cb13-94" aria-hidden="true" tabindex="-1"></a>    sampled_elements <span class="op">=</span> grouped.<span class="bu">apply</span>(<span class="kw">lambda</span> x: x.sample(<span class="bu">min</span>(num_samples_per_class, <span class="bu">len</span>(x))))</span>
<span id="cb13-95"><a href="#cb13-95" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> sampled_elements[<span class="st">'input'</span>], sampled_elements[<span class="st">'target'</span>]</span></code><button title="Copier vers le presse-papier" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
</section>
<section id="training" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="training">Training</h2>
<section id="evaluations" class="level3">
<h3 class="anchored" data-anchor-id="evaluations">Evaluations</h3>
<p>To evaluate our model, we will primarily use recall and a custom metric that we will call F2. Recall measures the ability of the model to correctly identify all relevant instances (true positives) from the dataset and is calculated as TP/(TP + FN), where TP stands for true positives and FN stands for false negatives.</p>
<p>The custom metric, F2, is designed to provide a more comprehensive evaluation of the model’s performance by balancing the detection of the positive class and minimizing errors. The F2 score is calculated as TP/(TP + FN + FP), where FP stands for false positives. This metric helps evaluate the model’s capacity to detect the positive class correctly while accounting for both false negatives and false positives. By considering both types of errors, the F2 metric ensures that the model is not only identifying positive instances accurately but also minimizing the incorrect classification of negative instances as positive. This balanced approach provides a more nuanced assessment of the model’s overall effectiveness.</p>
<hr>
</section>
<section id="modeling" class="level3">
<h3 class="anchored" data-anchor-id="modeling">Modeling</h3>
<p>For simplicity’s sake, I’ll use the distill version of Camembert model here, but you’re free to use any of the models below.</p>
<div id="cell-29" class="cell" data-execution="{&quot;iopub.status.busy&quot;:&quot;2024-05-16T22:48:47.588511Z&quot;,&quot;iopub.execute_input&quot;:&quot;2024-05-16T22:48:47.588779Z&quot;,&quot;iopub.status.idle&quot;:&quot;2024-05-16T22:48:47.597717Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2024-05-16T22:48:47.588757Z&quot;,&quot;shell.execute_reply&quot;:&quot;2024-05-16T22:48:47.596859Z&quot;}" data-trusted="true" data-execution_count="15">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>models <span class="op">=</span> {</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">'bert'</span>: <span class="st">"bert-base-uncased"</span>,</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">'gpt'</span>: <span class="st">"distilgpt2"</span>,</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">'flau'</span>: <span class="st">"flaubert/flaubert_base_uncased"</span>,</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">'cmb'</span>: <span class="st">"cmarkea/distilcamembert-base"</span>,</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copier vers le presse-papier" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="fine-tuning" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="fine-tuning">Fine tuning</h3>
<p>The next code might look a bit confusing at first, but let’s break it down step by step.</p>
<p>What we’re doing here is creating smaller subsets from our original training and test sets to build training, validation and test samples.</p>
<div id="cell-32" class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Grab the 'message' and 'target' columns from the training set and store them in X_train and y_train</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>X_train, y_train <span class="op">=</span> train[<span class="st">'message'</span>], train[<span class="st">'target'</span>]</span></code><button title="Copier vers le presse-papier" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Next, we split off a small portion of the original test set to use as our validation set. This is like keeping a small piece of pie aside before sharing the rest.</p>
<div id="cell-34" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>X_valid_sample, X_valid, y_valid_sample, y_valid <span class="op">=</span> train_test_split(test[<span class="st">'message'</span>], test[<span class="st">'target'</span>], test_size<span class="op">=</span><span class="fl">0.95</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>X_valid_sample.shape, X_valid.shape, y_valid_sample.shape, y_valid.shape</span></code><button title="Copier vers le presse-papier" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="16">
<pre><code>((9357,), (177783,), (9357,), (177783,))</code></pre>
</div>
</div>
<p>Then, we balance our training data. Imagine we have 6000 rows, and we want to make sure we have an equal number of positive and negative samples—3000 of each.</p>
<div id="cell-36" class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>X_train_sample, y_train_sample <span class="op">=</span> equal_class_sampling(X_train, y_train, <span class="dv">6000</span>)</span></code><button title="Copier vers le presse-papier" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Finally, we take another small slice of the test set to build our final test sample. Think of this as taking a tiny bit more of that pie for a taste test.</p>
<div id="cell-38" class="cell" data-outputid="936648c1-d053-418c-9b07-db17a7070612" data-execution_count="27">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Split the remaining validation set to create a small test sample (2% of X_valid and y_valid)</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>_, X_test_sample, _, y_test_sample <span class="op">=</span> train_test_split(X_valid, y_valid, test_size<span class="op">=</span><span class="fl">0.02</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>X_test_sample.shape</span></code><button title="Copier vers le presse-papier" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="27">
<pre><code>(3556,)</code></pre>
</div>
</div>
<p>By doing this, we ensure our model has balanced and representative data for training, validation, and final testing.</p>
<p>Now, we train, we validate and evaluate the model on the test set.</p>
<div id="cell-fig-cap-margin" class="cell page-columns page-full" data-outputid="04235890-1b1e-407a-ea6c-50bea8b53f85" data-execution_count="28">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> {}  <span class="co"># Initialize an empty dictionary to store training and evaluation history.</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>BATCH_SIZE <span class="op">=</span> <span class="dv">16</span>  <span class="co"># Define the batch size for data loaders.</span></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>LEARNING_RATE <span class="op">=</span> <span class="fl">1e-4</span>  <span class="co"># Set the learning rate for the optimizer.</span></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>weight_decay <span class="op">=</span> <span class="fl">1e-2</span>  <span class="co"># Set the weight decay (L2 regularization) for the optimizer.</span></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>EPOCHS <span class="op">=</span> <span class="dv">10</span>  <span class="co"># Set the number of epochs for training.</span></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare the dataset dictionary with training and testing samples.</span></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> {<span class="st">'X_train'</span>: X_train_sample, <span class="st">'y_train'</span>: y_train_sample, <span class="st">'X_test'</span>: X_test_sample, <span class="st">'y_test'</span>: y_test_sample}</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Get the model, tokenizer, training data loader, and testing data loader.</span></span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>model, tokz, train_loader, test_loader <span class="op">=</span> get_loader(models[<span class="st">'cmb'</span>], data, bs<span class="op">=</span>BATCH_SIZE, use_special_pad_token<span class="op">=</span><span class="va">True</span>, num_workers<span class="op">=</span><span class="dv">8</span>)</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>model.to(device)  <span class="co"># Move the model to the specified device (CPU or GPU).</span></span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>start_time <span class="op">=</span> time.time()  <span class="co"># Record the start time for training.</span></span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>train_model(model, train_loader, test_loader, history, num_epochs<span class="op">=</span>EPOCHS, lr<span class="op">=</span>LEARNING_RATE, early_stopping_patience<span class="op">=</span><span class="dv">2</span>, weight_decay<span class="op">=</span>weight_decay)  <span class="co"># Train the model.</span></span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>end_time <span class="op">=</span> time.time()  <span class="co"># Record the end time for training.</span></span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a>execution_time <span class="op">=</span> end_time <span class="op">-</span> start_time  <span class="co"># Calculate the execution time for training.</span></span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a>clear_output()  <span class="co"># Clear the output (useful in Jupyter notebooks to clear previous outputs).</span></span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Execution time:"</span>, execution_time, <span class="st">"seconds"</span>)  <span class="co"># Print the execution time for training.</span></span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a>start_time <span class="op">=</span> time.time()  <span class="co"># Record the start time for evaluation.</span></span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Evaluate the model on the validation dataset and optionally plot the training history.</span></span>
<span id="cb21-25"><a href="#cb21-25" aria-hidden="true" tabindex="-1"></a>evaluate_model(tokz, model, (X_valid_sample, y_valid_sample), history, device, bs <span class="op">=</span> BATCH_SIZE <span class="op">*</span> <span class="dv">2</span>, plot_train<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb21-26"><a href="#cb21-26" aria-hidden="true" tabindex="-1"></a>end_time <span class="op">=</span> time.time()  <span class="co"># Record the end time for evaluation.</span></span>
<span id="cb21-27"><a href="#cb21-27" aria-hidden="true" tabindex="-1"></a>execution_time <span class="op">=</span> end_time <span class="op">-</span> start_time  <span class="co"># Calculate the execution time for evaluation.</span></span>
<span id="cb21-28"><a href="#cb21-28" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Execution time:"</span>, execution_time, <span class="st">"seconds"</span>)  <span class="co"># Print the execution time for evaluation.</span></span></code><button title="Copier vers le presse-papier" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Execution time: 363.3319444656372 seconds</code></pre>
</div>
<div class="cell-output cell-output-display page-columns page-full">
<div id="fig-cap-margin" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-cap-margin-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="predicting_comment_reply_llm_files/figure-html/fig-cap-margin-output-2.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-cap-margin-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;2: Series of graphs depicting the performance metrics of the model. The metrics include Training Loss, Accuracy, Precision, Recall, and F2 score for both training and testing data.
</figcaption>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Test Metrics:
  Eval Accuracy: 0.6475366036122688
  Eval Precision: 0.23312101910828026
  Eval Recall: 0.7605985037406484
  Eval F2: 21.7184903868977
Execution time: 84.7105667591095 seconds</code></pre>
</div>
</div>
<p>Based on the performance of the model on two epochs, we can make the following analysis:</p>
<ol type="1">
<li><strong>Training Loss</strong>: Decreases from approximately 0.55 to 0.45, indicating improved performance during training.</li>
<li><strong>Accuracy</strong>: Shows a significant increase for training accuracy from about 0.70 to 0.78, while test accuracy slightly improves from around 0.62 to 0.64.</li>
<li><strong>Precision</strong>: Training precision rises from about 0.75 to 0.80, whereas test precision remains almost constant at around 0.21.</li>
<li><strong>Recall</strong>: Training recall increases from 0.60 to 0.75, while test recall decreases from 0.85 to 0.70, suggesting potential overfitting.</li>
<li><strong>F2</strong>: Indicates a decline in the F2 score from approximately 21.2 to 20.2, which means that the model is not generalizing from the training data to the test data.</li>
</ol>
<section id="test-metrics" class="level6">
<h6 class="anchored" data-anchor-id="test-metrics">Test Metrics:</h6>
<ol type="1">
<li><strong>Eval Accuracy</strong>: 0.6475, which indicates the model’s ability to correctly predict test data is moderate but lower compared to training accuracy.</li>
<li><strong>Eval Precision</strong>: 0.2331, which is significantly lower than the training precision, suggesting the model struggles with false positives on the test set.</li>
<li><strong>Eval Recall</strong>: 0.7606, which is relatively high and close to the training recall, showing the model still performs well in identifying most positive instances on the test set.</li>
<li><strong>Eval F2</strong>: 21.7185, which remains high, indicating that despite high recall, the model struggles with false positives.</li>
</ol>
</section>
<section id="conclusion" class="level6">
<h6 class="anchored" data-anchor-id="conclusion">Conclusion:</h6>
<ul>
<li><strong>Overfitting</strong>: The discrepancy between training and test precision suggests overfitting. The model performs well on the training data but struggles with generalization, leading to lower performance on unseen data.</li>
<li><strong>F2 score</strong>: The model prioritizes recall over precision. This is evident from the high recall but low precision on the test set. This behavior is further reflected in the F2 score, which is low, indicating many false positives.</li>
</ul>
<p>This analysis suggest that there is a problem with our model, because we need a model that should perform well on unseen data with low errors.</p>
</section>
<section id="why-is-this-important" class="level6">
<h6 class="anchored" data-anchor-id="why-is-this-important">Why is this important?</h6>
<p>Well, imagine that we will deploy our model in a real-world application. We don’t want to miss comments that might receive a response because we could use them to increase traffic on our site or social media. In that case, a model that detects positive instances well with minimal false positives is acceptable. However, our model currently has many false positives, which can be problematic.</p>
</section>
<section id="practical-implications" class="level6 page-columns page-full">
<h6 class="anchored" data-anchor-id="practical-implications">Practical Implications:</h6>
<ul>
<li>Business Impact: If the model is used in an application like content moderation or customer feedback analysis, high false positives mean that many irrelevant comments would be flagged for response. This can lead to inefficient use of resources and missed opportunities to engage with truly relevant comments.</li>
<li>User Experience: In applications like spam detection, a high number of false positives can frustrate users, as legitimate messages may be incorrectly flagged as spam.</li>
<li>Operational Efficiency: For customer service applications, responding to false positives wastes time and effort that could be better spent addressing genuine issues.</li>
</ul>
<p>But, let’s try with more data in our training set to see the impact on the model performance. We will initialise a new model and train it on 10000 comments.</p>
<div id="cell-43" class="cell" data-outputid="af75dd9b-263b-4e8b-c489-9a39062f9e47">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>X_train, y_train <span class="op">=</span> train[<span class="st">'message'</span>], train[<span class="st">'target'</span>]</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>X_train_sample, y_train_sample <span class="op">=</span> equal_class_sampling(X_train, y_train, <span class="dv">10000</span>)</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>_, X_test_sample, _, y_test_sample <span class="op">=</span> train_test_split(X_valid, y_valid, test_size<span class="op">=</span><span class="fl">0.02</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span></code><button title="Copier vers le presse-papier" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="cell-fig-cap-margin2" class="cell page-columns page-full" data-outputid="ded74fd0-2a4a-42d1-e16d-ec39b5198250" data-execution_count="30">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> {}</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>BATCH_SIZE <span class="op">=</span> <span class="dv">16</span></span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>LEARNING_RATE <span class="op">=</span> <span class="fl">1e-4</span></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>weight_decay <span class="op">=</span> <span class="fl">1e-2</span></span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>EPOCHS <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> {<span class="st">'X_train'</span>: X_train_sample, <span class="st">'y_train'</span>: y_train_sample, <span class="st">'X_test'</span>: X_test_sample, <span class="st">'y_test'</span>: y_test_sample}</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>model, tokz, train_loader, test_loader <span class="op">=</span> get_loader(models[<span class="st">'cmb'</span>], data, bs<span class="op">=</span>BATCH_SIZE, use_special_pad_token<span class="op">=</span><span class="va">True</span>, num_workers<span class="op">=</span><span class="dv">8</span>)</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>model.to(device)</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a>start_time <span class="op">=</span> time.time()</span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a>train_model(model, train_loader, test_loader, history, num_epochs<span class="op">=</span>EPOCHS, lr<span class="op">=</span>LEARNING_RATE, early_stopping_patience<span class="op">=</span><span class="dv">2</span>, weight_decay<span class="op">=</span>weight_decay)</span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a>end_time <span class="op">=</span> time.time()</span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a>execution_time <span class="op">=</span> end_time <span class="op">-</span> start_time</span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a>clear_output()</span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Execution time:"</span>, execution_time, <span class="st">"seconds"</span>)</span>
<span id="cb25-17"><a href="#cb25-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-18"><a href="#cb25-18" aria-hidden="true" tabindex="-1"></a>start_time <span class="op">=</span> time.time()</span>
<span id="cb25-19"><a href="#cb25-19" aria-hidden="true" tabindex="-1"></a>evaluate_model(tokz, model, (X_valid_sample, y_valid_sample), history, device, bs <span class="op">=</span> BATCH_SIZE <span class="op">*</span> <span class="dv">2</span>, plot_train<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb25-20"><a href="#cb25-20" aria-hidden="true" tabindex="-1"></a>end_time <span class="op">=</span> time.time()</span>
<span id="cb25-21"><a href="#cb25-21" aria-hidden="true" tabindex="-1"></a>execution_time <span class="op">=</span> end_time <span class="op">-</span> start_time</span>
<span id="cb25-22"><a href="#cb25-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Execution time:"</span>, execution_time, <span class="st">"seconds"</span>)</span></code><button title="Copier vers le presse-papier" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Execution time: 1122.6102643013 seconds</code></pre>
</div>
<div class="cell-output cell-output-display page-columns page-full">
<div id="fig-cap-margin2" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-cap-margin2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="predicting_comment_reply_llm_files/figure-html/fig-cap-margin2-output-2.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-cap-margin2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;3: Series of graphs depicting the performance metrics of the model. The metrics include Training Loss, Accuracy, Precision, Recall, and F2 score for both training and testing data.
</figcaption>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Test Metrics:
  Eval Accuracy: 0.6856898578604254
  Eval Precision: 0.25793871866295265
  Eval Recall: 0.769742310889443
  Eval F2: 23.946211533488494
Execution time: 84.70709776878357 seconds</code></pre>
</div>
</div>
<p>The F2 score improved from 21% to 23%. But can we conclude that it’s the increased training set that induces these results?</p>
<p>Let’s try it with a larger training set.</p>
<div id="cell-46" class="cell" data-outputid="2c81ea7b-c84f-4e90-aed8-3d1922e1fefe">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>X_train, y_train <span class="op">=</span> train[<span class="st">'message'</span>], train[<span class="st">'target'</span>]</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>X_train_sample, y_train_sample <span class="op">=</span> equal_class_sampling(X_train, y_train, <span class="dv">15000</span>)</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>_, X_test_sample, _, y_test_sample <span class="op">=</span> train_test_split(X_valid, y_valid, test_size<span class="op">=</span><span class="fl">0.02</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span></code><button title="Copier vers le presse-papier" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<div id="cell-fig-cap-margin3" class="cell page-columns page-full" data-outputid="76cc62cb-0659-475d-a63c-fe92852e4214" data-execution_count="35">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>history <span class="op">=</span> {}</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>BATCH_SIZE <span class="op">=</span> <span class="dv">32</span></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>LEARNING_RATE <span class="op">=</span> <span class="fl">1e-4</span></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>weight_decay <span class="op">=</span> <span class="fl">1e-2</span></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>EPOCHS <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>data <span class="op">=</span> {<span class="st">'X_train'</span>: X_train_sample, <span class="st">'y_train'</span>: y_train_sample, <span class="st">'X_test'</span>: X_test_sample, <span class="st">'y_test'</span>: y_test_sample}</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>model, tokz, train_loader, test_loader <span class="op">=</span> get_loader(models[<span class="st">'cmb'</span>], data, bs<span class="op">=</span>BATCH_SIZE, use_special_pad_token<span class="op">=</span><span class="va">True</span>, num_workers<span class="op">=</span><span class="dv">8</span>)</span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>model.to(device)</span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a>start_time <span class="op">=</span> time.time()</span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a>train_model(model, train_loader, test_loader, history, num_epochs<span class="op">=</span>EPOCHS, lr<span class="op">=</span>LEARNING_RATE, early_stopping_patience<span class="op">=</span><span class="dv">2</span>, weight_decay<span class="op">=</span>weight_decay)</span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a>end_time <span class="op">=</span> time.time()</span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a>execution_time <span class="op">=</span> end_time <span class="op">-</span> start_time</span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a>clear_output()</span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Execution time:"</span>, execution_time, <span class="st">"seconds"</span>)</span>
<span id="cb29-17"><a href="#cb29-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-18"><a href="#cb29-18" aria-hidden="true" tabindex="-1"></a>start_time <span class="op">=</span> time.time()</span>
<span id="cb29-19"><a href="#cb29-19" aria-hidden="true" tabindex="-1"></a>evaluate_model(tokz, model, (X_valid_sample, y_valid_sample), history, device, bs <span class="op">=</span> BATCH_SIZE <span class="op">*</span> <span class="dv">2</span>, plot_train<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb29-20"><a href="#cb29-20" aria-hidden="true" tabindex="-1"></a>end_time <span class="op">=</span> time.time()</span>
<span id="cb29-21"><a href="#cb29-21" aria-hidden="true" tabindex="-1"></a>execution_time <span class="op">=</span> end_time <span class="op">-</span> start_time</span>
<span id="cb29-22"><a href="#cb29-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"Execution time:"</span>, execution_time, <span class="st">"seconds"</span>)</span></code><button title="Copier vers le presse-papier" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stdout">
<pre><code>Execution time: 1914.5363965034485 seconds</code></pre>
</div>
<div class="cell-output cell-output-display page-columns page-full">
<div id="fig-cap-margin3" class="quarto-float quarto-figure quarto-figure-center anchored page-columns page-full">
<figure class="quarto-float quarto-float-fig figure page-columns page-full">
<div aria-describedby="fig-cap-margin3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="predicting_comment_reply_llm_files/figure-html/fig-cap-margin3-output-2.png" class="img-fluid figure-img">
</div>
<figcaption class="quarto-float-caption-margin quarto-float-caption quarto-float-fig margin-caption" id="fig-cap-margin3-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4: Series of graphs depicting the performance metrics of the model. The metrics include Training Loss, Accuracy, Precision, Recall, and F2 score for both training and testing data.
</figcaption>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Test Metrics:
  Eval Accuracy: 0.7079192048733568
  Eval Precision: 0.26705237515225333
  Eval Recall: 0.7290108063175395
  Eval F2: 24.293628808864266
Execution time: 85.33442664146423 seconds</code></pre>
</div>
</div>
<p>On test set, the F2 score of the model improve again from 23% to 24%.</p>
</section>
<section id="conclusion-1" class="level6">
<h6 class="anchored" data-anchor-id="conclusion-1">Conclusion:</h6>
<p>The increase in the training set size helps the model generalize better to the test data, reducing overfitting and improving its ability to balance precision and recall effectively.</p>
</section>
</section>
</section>
<section id="takeaways" class="level2">
<h2 class="anchored" data-anchor-id="takeaways">Takeaways</h2>
<ol type="1">
<li><p><strong>Dataset Analysis is Crucial</strong>: Always begin by analyzing your dataset. Understanding the distribution and characteristics of your data helps in making informed decisions about model training and evaluation. In scenarios with limited resources, generating more data for the underrepresented class might not be feasible. Instead, sampling equal numbers of comments from each class for the training set can help reduce bias towards the overrepresented class.</p></li>
<li><p><strong>Balanced Training, Unbalanced Validation</strong>: While balancing the training set by equal sampling is important to reduce bias, the validation set should remain unbalanced. This approach ensures that the model’s performance is evaluated in a realistic manner, reflecting its ability to generalize to the true distribution of the data.</p></li>
<li><p><strong>Resource-Based Training Strategy</strong>: Define your training strategy based on the available resources. When computational power or time is limited, working with a smaller, balanced sample of the dataset is a practical approach. This allows for iterative experimentation and tuning without the overhead of processing the entire dataset.</p></li>
<li><p><strong>Problem-Specific Metrics</strong>: Choose evaluation metrics that align with your problem’s objectives. For instance, in this scenario, the F2 score (F2 = tp / (tp + 2 * fn + fp)) is used to evaluate model performance by balancing the detection of the positive class and minimizing errors.</p></li>
<li><p><strong>Initial Model Performance</strong>: After the first round of training, the F2 score indicates that the model prioritizes recall over precision. This is evidenced by the high recall but low precision on the test set.</p></li>
<li><p><strong>Impact of False Positives</strong>: High false positives can be problematic in real-world applications. They can lead to inefficient use of resources and missed opportunities to engage with truly relevant comments. This highlights the need for a balance between precision and recall.</p></li>
<li><p><strong>Training Set Size and Generalization</strong>: Increasing the size of the training set helps the model generalize better to the test data. A larger training set reduces overfitting and enhances the model’s ability to balance precision and recall effectively. This results in improved overall performance and more reliable predictions.</p></li>
<li><p><strong>Choosing the Right Model</strong>: Select a model that is suitable for your specific problem. For instance, since the dataset consists of French text, using CamemBERT, a model specifically designed for the French language, is an appropriate choice.</p></li>
<li><p><strong>Hyperparameter Tuning</strong>: Finding the optimal hyperparameters for your model is crucial and often involves extensive experimentation. Before finalizing the model, numerous combinations were tested to identify the best-performing configuration. Hyperparameter tuning is more of an art than a strict recipe, requiring intuition and experience to achieve the best results.</p></li>
</ol>


</section>

<a onclick="window.scrollTo(0, 0); return false;" role="button" id="quarto-back-to-top"><i class="bi bi-arrow-up"></i> Retour au sommet</a></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copié");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copié");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/amenalahassa\.github\.io\/amenalahassa\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p>Copyright 2024</p>
<div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/amenalahassa/amenalahassa/issues/new" class="toc-action"><i class="bi bi-github"></i>Faire part d'un problème</a></li></ul></div><div class="cookie-consent-footer"><a href="#" id="open_preferences_center">Cookie Preferences</a></div></div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




<script src="../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>