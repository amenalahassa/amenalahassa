[
  {
    "objectID": "hello.html",
    "href": "hello.html",
    "title": "Quarto Basics",
    "section": "",
    "text": "For a demonstration of a line plot on a polar axis, see Figure 1.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nr = np.arange(0, 2, 0.01)\ntheta = 2 * np.pi * r\nfig, ax = plt.subplots(\n  subplot_kw = {'projection': 'polar'} \n)\nax.plot(theta, r)\nax.set_rticks([0.5, 1, 1.5, 2])\nax.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nFigure 1: A line plot on a polar axis"
  },
  {
    "objectID": "hello.html#polar-axis",
    "href": "hello.html#polar-axis",
    "title": "Quarto Basics",
    "section": "",
    "text": "For a demonstration of a line plot on a polar axis, see Figure 1.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nr = np.arange(0, 2, 0.01)\ntheta = 2 * np.pi * r\nfig, ax = plt.subplots(\n  subplot_kw = {'projection': 'polar'} \n)\nax.plot(theta, r)\nax.set_rticks([0.5, 1, 1.5, 2])\nax.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nFigure 1: A line plot on a polar axis"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "tagnon",
    "section": "",
    "text": "Predicting Reply under Comment with LLM\n\n\n\n\n\n\nLLM\n\n\nClassification\n\n\n\nnotebook\n\n\n\n\n\n18 mai 2024\n\n\nKonrad ALAHASSA\n\n\n\n\n\n\nAucun article correspondant\n\n Retour au sommet",
    "crumbs": [
      "Blog"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Konrad Tagnon Amen ALAHASSA",
    "section": "",
    "text": "AI Developer Fluent in Machine Learning and Web Technologies, À vos services… :)",
    "crumbs": [
      "L'auteur"
    ]
  },
  {
    "objectID": "about.html#experiences",
    "href": "about.html#experiences",
    "title": "Konrad Tagnon Amen ALAHASSA",
    "section": "Experiences",
    "text": "Experiences\n\nLead Developer | Sept 2022 - Jul 2023\nAgroSfer | Cotonou, Bénin\nLead development teams in creating a dynamic data aggregation system for enhanced dashboard analytics. Utilized Angular, Laravel, and MongoDB technologies.\n\n\nFront-end Developer | Jun 2021 - Sept 2022\nAgroSfer | Cotonou, Bénin\nStudied advanced software systems, focusing on practical and theoretical aspects of software engineering in Benin.\n\n\nInternship in Web Development | Mars 2021 - Mai 2021\nLa Vedette Media Digital | Cotonou, Bénin\nWorking on the development of a web platform for project management.\n\n\nInternship in Web Development | June 2020 - June 2018\nNAUTILUS TECHNOLOGY | Cotonou, Bénin\nInternship role focusing on web development using JavaScript, Angular, Laravel, and Git, solidifying foundational web development skills.",
    "crumbs": [
      "L'auteur"
    ]
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "Konrad Tagnon Amen ALAHASSA",
    "section": "Education",
    "text": "Education\n\nMaîtrise en informatique - Intelligence Artificielle | Since Sept 2023\nUniversité Laval | Québec, CA\nPursuing a Master’s degree focusing on Artificial Intelligence, enhancing skills in complex AI systems and machine learning implementations.\n\n\nSystèmes informatiques et Logiciels | Oct 2018 - Jul 2021\nLes COURS SONOU | Abomey-Calavi, Bénin\nStudied advanced software systems, focusing on practical and theoretical aspects of software engineering in Benin.\n\n\nBaccalauréat Science Maths | Août 2018\nCEG Application | Porto-Novo, Bénin\nGraduated with a focus on Mathematics and Science, forming a strong analytical foundation.",
    "crumbs": [
      "L'auteur"
    ]
  },
  {
    "objectID": "about.html#skills",
    "href": "about.html#skills",
    "title": "Konrad Tagnon Amen ALAHASSA",
    "section": "Skills",
    "text": "Skills\nPython, Matplotlib, Seaborn, Numpy, Pandas, Pytorch, Tensorflow, Keras, timm, fastai, fastcore, torchvision, Poutyne, SPSS Modeler, RStudio, PHP, Javascript, C, C++, SQL, Mysql, Firebase, MongoDB, Web Services, APIs Rest, Git, DevOps, CI/CD, and more…",
    "crumbs": [
      "L'auteur"
    ]
  },
  {
    "objectID": "about.html#online-courses",
    "href": "about.html#online-courses",
    "title": "Konrad Tagnon Amen ALAHASSA",
    "section": "Online courses",
    "text": "Online courses\n\nFrom Engineer to Technical Manager: A Survival Guide, Sundog Education\nUdemy - 2023",
    "crumbs": [
      "L'auteur"
    ]
  },
  {
    "objectID": "posts/predicting_comment_reply_llm.html",
    "href": "posts/predicting_comment_reply_llm.html",
    "title": "Predicting Reply under Comment with LLM",
    "section": "",
    "text": "This notebook is about predicting if a comment will have a reply base or not using LLM. I use here, a dataset constituate of a comment under posts of Le Soleil Page on Facebook. You will find a complete description and analyse of this dataset here. I use a prepared version of the original dataset, which contains news features about each comment."
  },
  {
    "objectID": "posts/predicting_comment_reply_llm.html#context",
    "href": "posts/predicting_comment_reply_llm.html#context",
    "title": "Predicting Reply under Comment with LLM",
    "section": "",
    "text": "This notebook is about predicting if a comment will have a reply base or not using LLM. I use here, a dataset constituate of a comment under posts of Le Soleil Page on Facebook. You will find a complete description and analyse of this dataset here. I use a prepared version of the original dataset, which contains news features about each comment."
  },
  {
    "objectID": "posts/predicting_comment_reply_llm.html#dependence",
    "href": "posts/predicting_comment_reply_llm.html#dependence",
    "title": "Predicting Reply under Comment with LLM",
    "section": "Dependence",
    "text": "Dependence\n\n\nCode\n!pip install torchsampler\n!pip install sacremoses\n\n\n\n\nCode\nimport transformers, torch\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer\nfrom torch.utils.data import Dataset\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\nfrom torchsampler import ImbalancedDatasetSampler\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\nimport pandas as pd\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom IPython.display import clear_output\nimport matplotlib.pyplot as plt\nimport multiprocessing as mp\nimport time\n\n# warnings.filterwarnings('ignore')\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nmp.cpu_count()\n\n\n\n\nCode\nfrom google.colab import drive\ndrive.mount('/content/drive')\n\n\nMounted at /content/drive"
  },
  {
    "objectID": "posts/predicting_comment_reply_llm.html#about-the-datasets",
    "href": "posts/predicting_comment_reply_llm.html#about-the-datasets",
    "title": "Predicting Reply under Comment with LLM",
    "section": "About the datasets",
    "text": "About the datasets\n\nDatasets\n\n\nCode\ndirpath = '/content/drive/MyDrive/DataSets/big_data/datasets' # specify here the path to the dataset\ntrain = pd.read_csv(dirpath + '/split/train_dataset.csv', index_col=0)\ntest = pd.read_csv(dirpath + '/split/valid_dataset.csv', index_col=0)\nvalid = pd.read_csv(dirpath + '/valid_dataset.csv', index_col=0)\n\n\n\n\nKeep in mind\nSome litle notes about the dataset I use. First, it contains almost millions lines\n\n\nCode\ndataset = pd.concat([train, test])\nprint(f'Dataset shape: {dataset.shape}')\n\n\nDataset shape: (935698, 68)\n\n\nNext, it important to note that our dataset is heavy unbalanced. The following plot show that there are only ~13% of comment with reply.\n\n\nCode\ndataset['target'].value_counts(normalize=True)\n\n\ntarget\nFalse    0.876036\nTrue     0.123964\nName: proportion, dtype: float64\n\n\n\n\nCode\ndataset['target'].value_counts().plot(kind='bar')\n\n\n\n\n\n\n\n\n\nIt is important to find a way to mitigate those two problems. For the first one, we can only use undersamplig. It offers the advantage to control the amount of data that we will use in finetuning step.\nThe undersampling also help to solve the second problem. At first time, having so much data to train our model could have be an advantage. But on limited ressource, it will take a lot of time to run only one epoch of that. And, we are also limited on quantity of items in our batch. This one is limited by the capacity of our RAM. So, for my modest experience, I will only train and test on a small subset of the whole dataset. I use equal sampling, to sample the same amout of the items for each class."
  },
  {
    "objectID": "posts/predicting_comment_reply_llm.html#classes-and-functions",
    "href": "posts/predicting_comment_reply_llm.html#classes-and-functions",
    "title": "Predicting Reply under Comment with LLM",
    "section": "Classes and functions",
    "text": "Classes and functions\n\n\nCode\nclass CommentDataset(Dataset):\n    def __init__(self, message, labels, tokenizer):\n        self.message = message\n        self.labels = labels\n        self.tokenizer = tokenizer\n\n    def get_labels(self):\n        return self.labels\n\n    def __len__(self):\n        return len(self.message)\n\n    def __getitem__(self, idx):\n        text = self.message[idx]\n        label = self.labels[idx]\n\n        inputs = self.tokenizer.encode_plus(text, None, add_special_tokens=True, padding='max_length', return_token_type_ids=True, truncation=True)\n\n        return {\n            'input_ids': torch.tensor(inputs['input_ids'], dtype=torch.long),\n            'attention_mask': torch.tensor(inputs['attention_mask'], dtype=torch.long),\n            'token_type_ids': torch.tensor(inputs[\"token_type_ids\"], dtype=torch.long),\n            'labels': torch.tensor(label, dtype=torch.float)\n        }\n\n\n\n\n\nCode\ndef train_model(model, train_dataloader, test_dataloader, history={}, num_epochs=5, lr=5e-5, early_stopping_patience=3, weight_decay=0.01):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n    scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=1)  # ReduceLROnPlateau scheduler\n    loss_fn = torch.nn.BCEWithLogitsLoss()  # Binary Cross-Entropy Loss\n\n    history['train_loss'] = []\n    history['train_accuracy'] = []\n    history['train_precision'] = []\n    history['train_recall'] = []\n    history['test_accuracy'] = []\n    history['test_precision'] = []\n    history['test_recall'] = []\n    history['epochs'] = []\n    history['test_loss'] = []\n    history['valid_score'] = []\n    best_valid_score = 0\n    early_stopping_counter = 0\n\n    for epoch in range(num_epochs):\n        model.train()\n        train_loss = 0.0\n        train_preds = []\n        train_labels = []\n\n        # Training loop\n        for _, batch in enumerate(tqdm(train_dataloader, desc=f'Epoch {epoch + 1}/{num_epochs}')):\n            optimizer.zero_grad()\n\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            token_type_ids = batch['token_type_ids'].to(device)\n            labels = batch['labels'].to(device)\n\n            outputs = model(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n            logits = outputs.logits.squeeze(1)\n            loss = loss_fn(logits, labels)\n            loss.backward()\n            optimizer.step()\n\n            train_loss += loss.item()\n            train_preds.extend((logits &gt; 0.5).int().tolist())\n            train_labels.extend(labels.tolist())\n\n        # Calculate metrics on training set\n        train_accuracy = accuracy_score(train_labels, train_preds)\n        train_precision = precision_score(train_labels, train_preds, average='binary')\n        train_recall = recall_score(train_labels, train_preds, average='binary')\n\n        # Evaluation loop\n        model.eval()\n        test_preds = []\n        test_labels = []\n        test_loss = 0.0\n\n        with torch.no_grad():\n            for batch in test_dataloader:\n\n                input_ids = batch['input_ids'].to(device)\n                attention_mask = batch['attention_mask'].to(device)\n                token_type_ids = batch['token_type_ids'].to(device)\n                labels = batch['labels'].to(device)\n                outputs = model(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n                logits = outputs.logits.squeeze(1)\n                loss = loss_fn(logits, labels)\n\n                test_loss += loss.item()\n                test_preds.extend((logits &gt; 0.5).int().tolist())\n                test_labels.extend(labels.tolist())\n\n        # Calculate metrics on test set\n        test_accuracy = accuracy_score(test_labels, test_preds)\n        test_precision = precision_score(test_labels, test_preds, average='binary')\n        test_recall = recall_score(test_labels, test_preds, average='binary')\n        tn, fp, fn, tp = confusion_matrix(test_labels, test_preds).ravel()\n        valid_score = (tp / (tp + fp + fn)) * 100\n\n        # Update learning rate scheduler\n        scheduler.step(valid_score)\n\n        history['epochs'].append(epoch + 1)\n\n        history['train_loss'].append(train_loss / len(train_dataloader))\n        history['train_accuracy'].append(train_accuracy)\n        history['train_precision'].append(train_precision)\n        history['train_recall'].append(train_recall)\n\n        history['test_loss'].append(test_loss / len(test_dataloader))\n        history['test_accuracy'].append(test_accuracy)\n        history['test_precision'].append(test_precision)\n        history['test_recall'].append(test_recall)\n        history['valid_score'].append(valid_score)\n\n        print(f\"Epoch {epoch + 1}/{num_epochs}:\")\n\n        print(f\"  Train Loss: {train_loss / len(train_dataloader)}\")\n        print(f\"  Test Loss: {test_loss / len(test_dataloader)}\")\n        print(f\"  Train Accuracy: {train_accuracy}\")\n        print(f\"  Train Precision: {train_precision}\")\n        print(f\"  Train Recall: {train_recall}\")\n\n        print(f\"  Test Accuracy: {test_accuracy}\")\n        print(f\"  Test Precision: {test_precision}\")\n        print(f\"  Test Recall: {test_recall}\")\n        print(f\"  Test F2: {valid_score}\")\n\n        # Early stopping\n        if valid_score &gt; best_valid_score:\n            best_valid_score = valid_score\n            early_stopping_counter = 0\n        else:\n            early_stopping_counter += 1\n\n        if early_stopping_counter &gt;= early_stopping_patience:\n            print(\"Early stopping triggered!\")\n            break\n\ndef test_model(tokz, model, valid_data, history, device, bs = 16):\n    model.eval()\n    test_preds = []\n    test_labels = []\n    test_loss = 0.0\n\n    valid_dataset = CommentDataset(valid_data[0].to_numpy(), valid_data[1].astype(int).to_numpy(), tokz)\n    test_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=bs, shuffle=True)\n    loss_fn = torch.nn.BCEWithLogitsLoss()  # Binary Cross-Entropy Loss\n\n    with torch.no_grad():\n        for batch in test_dataloader:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            token_type_ids = batch['token_type_ids'].to(device)\n            labels = batch['labels'].to(device)\n            outputs = model(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n            logits = outputs.logits.squeeze(1)\n            loss = loss_fn(logits, labels)\n\n            test_loss += loss.item()\n            test_preds.extend((logits &gt; 0.5).int().tolist())\n            test_labels.extend(labels.tolist())\n\n    test_accuracy = accuracy_score(test_labels, test_preds)\n    test_precision = precision_score(test_labels, test_preds)\n    test_recall = recall_score(test_labels, test_preds)\n    tn, fp, fn, tp = confusion_matrix(test_labels, test_preds).ravel()\n    history['valid_score'] = (tp / (tp + fp + fn)) * 100\n\n    print(\"Test Metrics:\")\n    print(f\"  Eval Accuracy: {test_accuracy}\")\n    print(f\"  Eval Precision: {test_precision}\")\n    print(f\"  Eval Recall: {test_recall}\")\n    print(f\"  Eval F2: {history['valid_score']}\")\n\n\n\n\nCode\ndef plot_history(history):\n    plt.figure(figsize=(17, 6))\n\n    epochs = history['epochs']\n    train_losses = history['train_loss']\n    test_loss = history['test_loss']\n    train_accuracies = history['train_accuracy']\n    test_accuracies = history['test_accuracy']\n    train_precisions = history['train_precision']\n    test_precisions = history['test_precision']\n    train_recall = history['train_recall']\n    test_recall = history['test_recall']\n    valid_score = history['valid_score']\n\n    plt.subplot(1, 5, 1)\n    plt.plot(epochs, train_losses, label='Training Loss')\n    plt.plot(epochs, test_loss, label='Test Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.title('Training Loss')\n\n    plt.subplot(1, 5, 2)\n    plt.plot(epochs, train_accuracies, label='Training Accuracy')\n    plt.plot(epochs, test_accuracies, label='Test Accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.title('Accuracy')\n    plt.legend()\n\n    plt.subplot(1, 5, 3)\n    plt.plot(epochs, train_precisions, label='Training Precision')\n    plt.plot(epochs, test_precisions, label='Test Precision')\n    plt.xlabel('Epochs')\n    plt.ylabel('Precision')\n    plt.title('Precision')\n    plt.legend()\n\n    plt.subplot(1, 5, 4)\n    plt.plot(epochs, train_recall, label='Training Recall')\n    plt.plot(epochs, test_recall, label='Test Recall')\n    plt.xlabel('Epochs')\n    plt.ylabel('Recall')\n    plt.title('Recall')\n    plt.legend()\n\n    plt.subplot(1, 5, 5)\n    plt.plot(epochs, valid_score, label='Training F2')\n    plt.xlabel('Epochs')\n    plt.ylabel('F2')\n    plt.title('F2')\n    plt.legend()\n\n    plt.tight_layout()\n    plt.show()\n    \ndef evaluate_model(tokz, model, valid_data, history, device, bs = 16, plot_train=True):\n    if plot_train:\n        plot_history(history)\n    test_model(tokz, model, valid_data, history, device, bs = bs)\n    \ndef get_loader(model_nm, dataset, bs = 100, under_sample=True, num_class = 1, use_pad_token=True, use_special_pad_token=False, num_workers=2):\n    X_train, y_train, X_test, y_test = dataset['X_train'], dataset['y_train'], dataset['X_test'], dataset['y_test']\n    tokz = AutoTokenizer.from_pretrained(model_nm)\n\n    model = AutoModelForSequenceClassification.from_pretrained(model_nm, num_labels = num_class)\n\n    if len(X_train) == 0:\n      return model, tokz, None, None\n\n    if use_pad_token:\n        tokz.pad_token = tokz.eos_token\n    if use_special_pad_token:\n        tokz.add_special_tokens({'pad_token': '[PAD]'})\n\n    model.resize_token_embeddings(len(tokz))\n\n    train_dataset = CommentDataset(X_train.to_numpy(), y_train.astype(int).to_numpy(), tokz)\n    test_dataset = CommentDataset(X_test.to_numpy(), y_test.astype(int).to_numpy(), tokz)\n\n    if under_sample:\n        train_loader = torch.utils.data.DataLoader(train_dataset, sampler=ImbalancedDatasetSampler(train_dataset), batch_size=bs, num_workers=num_workers, pin_memory=True)\n        test_loader = torch.utils.data.DataLoader(test_dataset, shuffle=True, batch_size=bs, num_workers=num_workers, pin_memory=True)\n    else:\n        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=bs, shuffle=True, num_workers=num_workers, pin_memory=True)\n        test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=bs, shuffle=True, num_workers=num_workers, pin_memory=True)\n\n    return model, tokz, train_loader, test_loader\n\ndef equal_class_sampling(input_features, target_labels, num_samples):\n    num_classes = len(target_labels.unique())\n    num_samples_per_class = num_samples // num_classes\n    dataset = pd.DataFrame({'input': input_features, 'target': target_labels})\n    grouped = dataset.groupby(['target'])\n    sampled_elements = grouped.apply(lambda x: x.sample(min(num_samples_per_class, len(x))))\n    return sampled_elements['input'], sampled_elements['target']"
  },
  {
    "objectID": "posts/predicting_comment_reply_llm.html#training",
    "href": "posts/predicting_comment_reply_llm.html#training",
    "title": "Predicting Reply under Comment with LLM",
    "section": "Training",
    "text": "Training\n\nEvaluations\nTo evaluate our model, we will use mainly use recall and a custom metrics, that we will call F2, and equal TP/(TP+FN+FP). The later help evaluate the capacity of the model to detect the positive class correctly, with no errors on both positive and negative instances.\n\n\nThe right model\nHere, for simplicity, I will use the Camembert base model, but you are a free to use any model below. From my experience, Camembert was the best, with small training (~50% of F2 on first three epochs when finetuning)\n\n\nCode\nmodels = {\n    'bert': \"bert-base-uncased\",\n    'gpt': \"distilgpt2\",\n    'flau': \"flaubert/flaubert_base_uncased\",\n    'cmb': \"cmarkea/distilcamembert-base\",\n}\n\n\n\n\nFine tuning\n\n\nCode\nX_valid_sample, X_valid, y_valid_sample, y_valid = train_test_split(test['message'], test['target'], test_size=0.95, random_state=42)\nX_valid_sample.shape, X_valid.shape, y_valid_sample.shape, y_valid.shape\n\n\n((9357,), (177783,), (9357,), (177783,))\n\n\n\n\nCode\nX_train, y_train = train['message'], train['target']\nX_train_sample, y_train_sample = equal_class_sampling(X_train, y_train, 6000)\n_, X_test_sample, _, y_test_sample = train_test_split(X_valid, y_valid, test_size=0.02, random_state=42)\nX_test_sample.shape\n\n\n(3556,)\n\n\n\n\nCode\nhistory = {}\nBATCH_SIZE = 16\nLEARNING_RATE = 1e-4\nweight_decay = 1e-2\nEPOCHS = 10\ndata = {'X_train': X_train_sample, 'y_train': y_train_sample, 'X_test': X_test_sample, 'y_test': y_test_sample}\nmodel, tokz, train_loader, test_loader = get_loader(models['cmb'], data, bs=BATCH_SIZE, use_special_pad_token=True, num_workers=8)\nmodel.to(device)\n\nstart_time = time.time()\ntrain_model(model, train_loader, test_loader, history, num_epochs=EPOCHS, lr=LEARNING_RATE, early_stopping_patience=2, weight_decay=weight_decay)\nend_time = time.time()\nexecution_time = end_time - start_time\n\nclear_output()\nprint(\"Execution time:\", execution_time, \"seconds\")\n\nstart_time = time.time()\nevaluate_model(tokz, model, (X_valid_sample, y_valid_sample), history, device, bs = BATCH_SIZE * 2, plot_train=True)\nend_time = time.time()\nexecution_time = end_time - start_time\nprint(\"Execution time:\", execution_time, \"seconds\")\n\n\nExecution time: 363.3319444656372 seconds\n\n\n\n\n\n\n\n\n\nTest Metrics:\n  Eval Accuracy: 0.6475366036122688\n  Eval Precision: 0.23312101910828026\n  Eval Recall: 0.7605985037406484\n  Eval F2: 21.7184903868977\nExecution time: 84.7105667591095 seconds\n\n\n\n\nCode\nX_train, y_train = train['message'], train['target']\nX_train_sample, y_train_sample = equal_class_sampling(X_train, y_train, 10000)\n_, X_test_sample, _, y_test_sample = train_test_split(X_valid, y_valid, test_size=0.02, random_state=42)\n\n\n\n\nCode\nhistory = {}\nBATCH_SIZE = 16\nLEARNING_RATE = 1e-4\nweight_decay = 1e-2\nEPOCHS = 10\ndata = {'X_train': X_train_sample, 'y_train': y_train_sample, 'X_test': X_test_sample, 'y_test': y_test_sample}\nmodel, tokz, train_loader, test_loader = get_loader(models['cmb'], data, bs=BATCH_SIZE, use_special_pad_token=True, num_workers=8)\nmodel.to(device)\n\nstart_time = time.time()\ntrain_model(model, train_loader, test_loader, history, num_epochs=EPOCHS, lr=LEARNING_RATE, early_stopping_patience=2, weight_decay=weight_decay)\nend_time = time.time()\nexecution_time = end_time - start_time\n\nclear_output()\nprint(\"Execution time:\", execution_time, \"seconds\")\n\nstart_time = time.time()\nevaluate_model(tokz, model, (X_valid_sample, y_valid_sample), history, device, bs = BATCH_SIZE * 2, plot_train=True)\nend_time = time.time()\nexecution_time = end_time - start_time\nprint(\"Execution time:\", execution_time, \"seconds\")\n\n\nExecution time: 1122.6102643013 seconds\n\n\n\n\n\n\n\n\n\nTest Metrics:\n  Eval Accuracy: 0.6856898578604254\n  Eval Precision: 0.25793871866295265\n  Eval Recall: 0.769742310889443\n  Eval F2: 23.946211533488494\nExecution time: 84.70709776878357 seconds\n\n\n\n\nCode\nX_train, y_train = train['message'], train['target']\nX_train_sample, y_train_sample = equal_class_sampling(X_train, y_train, 15000)\n_, X_test_sample, _, y_test_sample = train_test_split(X_valid, y_valid, test_size=0.02, random_state=42)\n\n\n\n\nCode\nhistory = {}\nBATCH_SIZE = 32\nLEARNING_RATE = 1e-4\nweight_decay = 1e-2\nEPOCHS = 10\ndata = {'X_train': X_train_sample, 'y_train': y_train_sample, 'X_test': X_test_sample, 'y_test': y_test_sample}\nmodel, tokz, train_loader, test_loader = get_loader(models['cmb'], data, bs=BATCH_SIZE, use_special_pad_token=True, num_workers=8)\nmodel.to(device)\n\nstart_time = time.time()\ntrain_model(model, train_loader, test_loader, history, num_epochs=EPOCHS, lr=LEARNING_RATE, early_stopping_patience=2, weight_decay=weight_decay)\nend_time = time.time()\nexecution_time = end_time - start_time\n\nclear_output()\nprint(\"Execution time:\", execution_time, \"seconds\")\n\nstart_time = time.time()\nevaluate_model(tokz, model, (X_valid_sample, y_valid_sample), history, device, bs = BATCH_SIZE * 2, plot_train=True)\nend_time = time.time()\nexecution_time = end_time - start_time\nprint(\"Execution time:\", execution_time, \"seconds\")\n\n\nExecution time: 1914.5363965034485 seconds\n\n\n\n\n\n\n\n\n\nTest Metrics:\n  Eval Accuracy: 0.7079192048733568\n  Eval Precision: 0.26705237515225333\n  Eval Recall: 0.7290108063175395\n  Eval F2: 24.293628808864266\nExecution time: 85.33442664146423 seconds"
  }
]