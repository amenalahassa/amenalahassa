[
  {
    "objectID": "hello.html",
    "href": "hello.html",
    "title": "Quarto Basics",
    "section": "",
    "text": "For a demonstration of a line plot on a polar axis, see Figure 1.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nr = np.arange(0, 2, 0.01)\ntheta = 2 * np.pi * r\nfig, ax = plt.subplots(\n  subplot_kw = {'projection': 'polar'} \n)\nax.plot(theta, r)\nax.set_rticks([0.5, 1, 1.5, 2])\nax.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nFigure 1: A line plot on a polar axis"
  },
  {
    "objectID": "hello.html#polar-axis",
    "href": "hello.html#polar-axis",
    "title": "Quarto Basics",
    "section": "",
    "text": "For a demonstration of a line plot on a polar axis, see Figure 1.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nr = np.arange(0, 2, 0.01)\ntheta = 2 * np.pi * r\nfig, ax = plt.subplots(\n  subplot_kw = {'projection': 'polar'} \n)\nax.plot(theta, r)\nax.set_rticks([0.5, 1, 1.5, 2])\nax.grid(True)\nplt.show()\n\n\n\n\n\n\n\n\nFigure 1: A line plot on a polar axis"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "AiLand",
    "section": "",
    "text": "Predicting Reply under Comment with LLM\n\n\n\n\n\n\n\n\n\n\n\n5 juin 2025\n\n\nKonrad ALAHASSA\n\n\n\n\n\n\nAucun article correspondant\n\n Retour au sommet",
    "crumbs": [
      "Blog"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Finley Malloc",
    "section": "",
    "text": "Finley Malloc is the Chief Data Scientist at Wengo Analytics. When not innovating on data platforms, Finley enjoys spending time unicycling and playing with her pet iguana.\n\n\nUniversity of California, San Diego | San Diego, CA PhD in Mathematics | Sept 2011 - June 2015\nMacalester College | St. Paul MA B.A in Economics | Sept 2007 - June 2011\n\n\n\nWengo Analytics | Head Data Scientist | April 2018 - present\nGeoScynce | Chief Analyst | Sept 2012 - April 2018\n\n \n  \n   \n  \n    \n     twitter\n  \n  \n    \n     Github",
    "crumbs": [
      "Qui suis-je ?"
    ]
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "Finley Malloc",
    "section": "",
    "text": "University of California, San Diego | San Diego, CA PhD in Mathematics | Sept 2011 - June 2015\nMacalester College | St. Paul MA B.A in Economics | Sept 2007 - June 2011",
    "crumbs": [
      "Qui suis-je ?"
    ]
  },
  {
    "objectID": "about.html#experience",
    "href": "about.html#experience",
    "title": "Finley Malloc",
    "section": "",
    "text": "Wengo Analytics | Head Data Scientist | April 2018 - present\nGeoScynce | Chief Analyst | Sept 2012 - April 2018",
    "crumbs": [
      "Qui suis-je ?"
    ]
  },
  {
    "objectID": "posts/predicting_comment_reply_llm.html",
    "href": "posts/predicting_comment_reply_llm.html",
    "title": "Predicting Reply under Comment with LLM",
    "section": "",
    "text": "This notebook is about predicting if a comment will have a reply base or not using LLM. I use here, a dataset constituate of a comment under posts of Le Soleil Page on Facebook. You will find a complete description and analyse of this dataset here. I use a prepared version of the original dataset, which contains news features about each comment."
  },
  {
    "objectID": "posts/predicting_comment_reply_llm.html#context",
    "href": "posts/predicting_comment_reply_llm.html#context",
    "title": "Predicting Reply under Comment with LLM",
    "section": "",
    "text": "This notebook is about predicting if a comment will have a reply base or not using LLM. I use here, a dataset constituate of a comment under posts of Le Soleil Page on Facebook. You will find a complete description and analyse of this dataset here. I use a prepared version of the original dataset, which contains news features about each comment."
  },
  {
    "objectID": "posts/predicting_comment_reply_llm.html#libs",
    "href": "posts/predicting_comment_reply_llm.html#libs",
    "title": "Predicting Reply under Comment with LLM",
    "section": "Libs",
    "text": "Libs\n\n\nCode\n!pip install torchsampler\n!pip install sacremoses\n\n\n\n\nCode\nfrom torch.utils.data import DataLoader\nimport transformers, torch\nfrom transformers import TrainingArguments,Trainer\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n\nfrom torch import nn\nfrom torch.utils.data import Dataset\nfrom sklearn import metrics\nfrom torch import cuda\nfrom transformers import TrainingArguments, Trainer\nfrom sklearn.metrics import f1_score, roc_auc_score, accuracy_score, precision_score, recall_score, confusion_matrix\nfrom transformers import EvalPrediction\nfrom torchsampler import ImbalancedDatasetSampler\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\nimport pandas as pd\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom IPython.display import clear_output\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nimport time\n\n# warnings.filterwarnings('ignore')\nimport multiprocessing as mp\nmp.cpu_count()\n\n\n\n\nCode\nfrom google.colab import drive\ndrive.mount('/content/drive')\n\n\nMounted at /content/drive"
  },
  {
    "objectID": "posts/predicting_comment_reply_llm.html#about-the-datasets",
    "href": "posts/predicting_comment_reply_llm.html#about-the-datasets",
    "title": "Predicting Reply under Comment with LLM",
    "section": "About the datasets",
    "text": "About the datasets\n\nDatasets\n::: {#cell-9 .cell _uuid=‘8f2839f25d086af736a60e9eeb907d3b93b6e0e5’ _cell_guid=‘b1076dfc-b9ad-4769-8c92-a6c4dae69d19’ execution=‘{“iopub.status.busy”:“2024-05-16T22:48:24.488214Z”,“iopub.execute_input”:“2024-05-16T22:48:24.488565Z”,“iopub.status.idle”:“2024-05-16T22:48:47.459472Z”,“shell.execute_reply.started”:“2024-05-16T22:48:24.488531Z”,“shell.execute_reply”:“2024-05-16T22:48:47.458694Z”}’ trusted=‘true’ execution_count=4}\n\nCode\ndirpath = '/content/drive/MyDrive/DataSets/big_data/datasets' # specify here the path to the dataset\ntrain = pd.read_csv(dirpath + '/split/train_dataset.csv', index_col=0)\ntest = pd.read_csv(dirpath + '/split/valid_dataset.csv', index_col=0)\nvalid = pd.read_csv(dirpath + '/valid_dataset.csv', index_col=0)\n\n:::\n\n\nKeep in mind\nSome litle notes about the dataset I use. First, it contains almost millions lines\n\n\nCode\ndataset = pd.concat([train, test])\nprint(f'Dataset shape: {dataset.shape}')\n\n\nDataset shape: (935698, 68)\n\n\nNext, it important to note that our dataset is heavy unbalanced. The following plot show that there are only ~13% of comment with reply.\n\n\nCode\ndataset['target'].value_counts(normalize=True)\n\n\ntarget\nFalse    0.876036\nTrue     0.123964\nName: proportion, dtype: float64\n\n\n\n\nCode\ndataset['target'].value_counts().plot(kind='bar')\n\n\n\n\n\n\n\n\n\nIt is important to find a way to mitigate those two problems. For the first one, we can only use undersamplig. It offers the advantage to control the amount of data that we will use in finetuning step.\nThe undersampling also help to solve the second problem. At first time, having so much data to train our model could have be an advantage. But on limited ressource, it will take a lot of time to run only one epoch of that. And, we are also limited on quantity of items in our batch. This one is limited by the capacity of our RAM. So, for my modest experience, I will only train and test on a small subset of the whole dataset. I use equal sampling, to sample the same amout of the items for each class."
  },
  {
    "objectID": "posts/predicting_comment_reply_llm.html#classes-and-functions",
    "href": "posts/predicting_comment_reply_llm.html#classes-and-functions",
    "title": "Predicting Reply under Comment with LLM",
    "section": "Classes and functions",
    "text": "Classes and functions\n\n\nCode\nclass CommentDataset(Dataset):\n    def __init__(self, message, labels, tokenizer):\n        self.message = message\n        self.labels = labels\n        self.tokenizer = tokenizer\n\n    def get_labels(self):\n        return self.labels\n\n    def __len__(self):\n        return len(self.message)\n\n    def __getitem__(self, idx):\n        text = self.message[idx]\n        label = self.labels[idx]\n\n        inputs = self.tokenizer.encode_plus(text, None, add_special_tokens=True, padding='max_length', return_token_type_ids=True, truncation=True)\n\n        return {\n            'input_ids': torch.tensor(inputs['input_ids'], dtype=torch.long),\n            'attention_mask': torch.tensor(inputs['attention_mask'], dtype=torch.long),\n            'token_type_ids': torch.tensor(inputs[\"token_type_ids\"], dtype=torch.long),\n            'labels': torch.tensor(label, dtype=torch.float)\n        }\n\n\n\n\n\nCode\ndef train_model(model, train_dataloader, test_dataloader, history={}, num_epochs=5, lr=5e-5, early_stopping_patience=3, weight_decay=0.01):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n    scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=1)  # ReduceLROnPlateau scheduler\n    loss_fn = torch.nn.BCEWithLogitsLoss()  # Binary Cross-Entropy Loss\n\n    history['train_loss'] = []\n    history['train_accuracy'] = []\n    history['train_precision'] = []\n    history['train_recall'] = []\n    history['test_accuracy'] = []\n    history['test_precision'] = []\n    history['test_recall'] = []\n    history['epochs'] = []\n    history['test_loss'] = []\n    history['valid_score'] = []\n    best_valid_score = 0\n    early_stopping_counter = 0\n\n    for epoch in range(num_epochs):\n        model.train()\n        train_loss = 0.0\n        train_preds = []\n        train_labels = []\n\n        # Training loop\n        for _, batch in enumerate(tqdm(train_dataloader, desc=f'Epoch {epoch + 1}/{num_epochs}')):\n            optimizer.zero_grad()\n\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            token_type_ids = batch['token_type_ids'].to(device)\n            labels = batch['labels'].to(device)\n\n            outputs = model(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n            logits = outputs.logits.squeeze(1)\n            loss = loss_fn(logits, labels)\n            loss.backward()\n            optimizer.step()\n\n            train_loss += loss.item()\n            train_preds.extend((logits &gt; 0.5).int().tolist())\n            train_labels.extend(labels.tolist())\n\n        # Calculate metrics on training set\n        train_accuracy = accuracy_score(train_labels, train_preds)\n        train_precision = precision_score(train_labels, train_preds, average='binary')\n        train_recall = recall_score(train_labels, train_preds, average='binary')\n\n        # Evaluation loop\n        model.eval()\n        test_preds = []\n        test_labels = []\n        test_loss = 0.0\n\n        with torch.no_grad():\n            for batch in test_dataloader:\n\n                input_ids = batch['input_ids'].to(device)\n                attention_mask = batch['attention_mask'].to(device)\n                token_type_ids = batch['token_type_ids'].to(device)\n                labels = batch['labels'].to(device)\n                outputs = model(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n                logits = outputs.logits.squeeze(1)\n                loss = loss_fn(logits, labels)\n\n                test_loss += loss.item()\n                test_preds.extend((logits &gt; 0.5).int().tolist())\n                test_labels.extend(labels.tolist())\n\n        # Calculate metrics on test set\n        test_accuracy = accuracy_score(test_labels, test_preds)\n        test_precision = precision_score(test_labels, test_preds, average='binary')\n        test_recall = recall_score(test_labels, test_preds, average='binary')\n        tn, fp, fn, tp = confusion_matrix(test_labels, test_preds).ravel()\n        valid_score = (tp / (tp + fp + fn)) * 100\n\n        # Update learning rate scheduler\n        scheduler.step(valid_score)\n\n        history['epochs'].append(epoch + 1)\n\n        history['train_loss'].append(train_loss / len(train_dataloader))\n        history['train_accuracy'].append(train_accuracy)\n        history['train_precision'].append(train_precision)\n        history['train_recall'].append(train_recall)\n\n        history['test_loss'].append(test_loss / len(test_dataloader))\n        history['test_accuracy'].append(test_accuracy)\n        history['test_precision'].append(test_precision)\n        history['test_recall'].append(test_recall)\n        history['valid_score'].append(valid_score)\n\n        print(f\"Epoch {epoch + 1}/{num_epochs}:\")\n\n        print(f\"  Train Loss: {train_loss / len(train_dataloader)}\")\n        print(f\"  Test Loss: {test_loss / len(test_dataloader)}\")\n        print(f\"  Train Accuracy: {train_accuracy}\")\n        print(f\"  Train Precision: {train_precision}\")\n        print(f\"  Train Recall: {train_recall}\")\n\n        print(f\"  Test Accuracy: {test_accuracy}\")\n        print(f\"  Test Precision: {test_precision}\")\n        print(f\"  Test Recall: {test_recall}\")\n        print(f\"  Test F2: {valid_score}\")\n\n        # Early stopping\n        if valid_score &gt; best_valid_score:\n            best_valid_score = valid_score\n            early_stopping_counter = 0\n        else:\n            early_stopping_counter += 1\n\n        if early_stopping_counter &gt;= early_stopping_patience:\n            print(\"Early stopping triggered!\")\n            break\n\n\n\n\nCode\ndef test_model(tokz, model, valid_data, history, device, bs = 16):\n    model.eval()\n    test_preds = []\n    test_labels = []\n    test_loss = 0.0\n\n    valid_dataset = CommentDataset(valid_data[0].to_numpy(), valid_data[1].astype(int).to_numpy(), tokz)\n    test_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=bs, shuffle=True)\n    loss_fn = torch.nn.BCEWithLogitsLoss()  # Binary Cross-Entropy Loss\n\n    with torch.no_grad():\n        for batch in test_dataloader:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            token_type_ids = batch['token_type_ids'].to(device)\n            labels = batch['labels'].to(device)\n            outputs = model(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n            logits = outputs.logits.squeeze(1)\n            loss = loss_fn(logits, labels)\n\n            test_loss += loss.item()\n            test_preds.extend((logits &gt; 0.5).int().tolist())\n            test_labels.extend(labels.tolist())\n\n    test_accuracy = accuracy_score(test_labels, test_preds)\n    test_precision = precision_score(test_labels, test_preds)\n    test_recall = recall_score(test_labels, test_preds)\n    tn, fp, fn, tp = confusion_matrix(test_labels, test_preds).ravel()\n    history['valid_score'] = (tp / (tp + fp + fn)) * 100\n\n    print(\"Test Metrics:\")\n    print(f\"  Eval Accuracy: {test_accuracy}\")\n    print(f\"  Eval Precision: {test_precision}\")\n    print(f\"  Eval Recall: {test_recall}\")\n    print(f\"  Eval F2: {history['valid_score']}\")\n\n\n\n\nCode\ndef plot_history(history):\n    plt.figure(figsize=(17, 6))\n\n    epochs = history['epochs']\n    train_losses = history['train_loss']\n    test_loss = history['test_loss']\n    train_accuracies = history['train_accuracy']\n    test_accuracies = history['test_accuracy']\n    train_precisions = history['train_precision']\n    test_precisions = history['test_precision']\n    train_recall = history['train_recall']\n    test_recall = history['test_recall']\n    valid_score = history['valid_score']\n\n    plt.subplot(1, 5, 1)\n    plt.plot(epochs, train_losses, label='Training Loss')\n    plt.plot(epochs, test_loss, label='Test Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.title('Training Loss')\n\n    plt.subplot(1, 5, 2)\n    plt.plot(epochs, train_accuracies, label='Training Accuracy')\n    plt.plot(epochs, test_accuracies, label='Test Accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.title('Accuracy')\n    plt.legend()\n\n    plt.subplot(1, 5, 3)\n    plt.plot(epochs, train_precisions, label='Training Precision')\n    plt.plot(epochs, test_precisions, label='Test Precision')\n    plt.xlabel('Epochs')\n    plt.ylabel('Precision')\n    plt.title('Precision')\n    plt.legend()\n\n    plt.subplot(1, 5, 4)\n    plt.plot(epochs, train_recall, label='Training Recall')\n    plt.plot(epochs, test_recall, label='Test Recall')\n    plt.xlabel('Epochs')\n    plt.ylabel('Recall')\n    plt.title('Recall')\n    plt.legend()\n\n    plt.subplot(1, 5, 5)\n    plt.plot(epochs, valid_score, label='Training F2')\n    plt.xlabel('Epochs')\n    plt.ylabel('F2')\n    plt.title('F2')\n    plt.legend()\n\n    plt.tight_layout()\n    plt.show()\n\n\n\n\nCode\ndef evaluate_model(tokz, model, valid_data, history, device, bs = 16, plot_train=True):\n    if plot_train:\n        plot_history(history)\n    test_model(tokz, model, valid_data, history, device, bs = bs)\n\n\n\n\nCode\ndef get_loader(model_nm, dataset, bs = 100, under_sample=True, num_class = 1, use_pad_token=True, use_special_pad_token=False, num_workers=2):\n    X_train, y_train, X_test, y_test = dataset['X_train'], dataset['y_train'], dataset['X_test'], dataset['y_test']\n    tokz = AutoTokenizer.from_pretrained(model_nm)\n\n    model = AutoModelForSequenceClassification.from_pretrained(model_nm, num_labels = num_class)\n\n    if len(X_train) == 0:\n      return model, tokz, None, None\n\n    if use_pad_token:\n        tokz.pad_token = tokz.eos_token\n    if use_special_pad_token:\n        tokz.add_special_tokens({'pad_token': '[PAD]'})\n\n    model.resize_token_embeddings(len(tokz))\n\n    train_dataset = CommentDataset(X_train.to_numpy(), y_train.astype(int).to_numpy(), tokz)\n    test_dataset = CommentDataset(X_test.to_numpy(), y_test.astype(int).to_numpy(), tokz)\n\n    if under_sample:\n        train_loader = torch.utils.data.DataLoader(train_dataset, sampler=ImbalancedDatasetSampler(train_dataset), batch_size=bs, num_workers=num_workers, pin_memory=True)\n        test_loader = torch.utils.data.DataLoader(test_dataset, shuffle=True, batch_size=bs, num_workers=num_workers, pin_memory=True)\n    else:\n        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=bs, shuffle=True, num_workers=num_workers, pin_memory=True)\n        test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=bs, shuffle=True, num_workers=num_workers, pin_memory=True)\n\n    return model, tokz, train_loader, test_loader\n\n\n\n\nCode\ndef equal_class_sampling(input_features, target_labels, num_samples):\n    num_classes = len(target_labels.unique())\n    num_samples_per_class = num_samples // num_classes\n    dataset = pd.DataFrame({'input': input_features, 'target': target_labels})\n    grouped = dataset.groupby(['target'])\n    sampled_elements = grouped.apply(lambda x: x.sample(min(num_samples_per_class, len(x))))\n    return sampled_elements['input'], sampled_elements['target']"
  },
  {
    "objectID": "posts/predicting_comment_reply_llm.html#training",
    "href": "posts/predicting_comment_reply_llm.html#training",
    "title": "Predicting Reply under Comment with LLM",
    "section": "Training",
    "text": "Training\n\nEvaluations\nTo evaluate our model, we will use mainly use recall and a custom metrics, that we will call F2, and equal TP/(TP+FN+FP). The later help evaluate the capacity of the model to detect the positive class correctly, with no errors on both positive and negative instances.\n\n\nThe right model\nHere, for simplicity, I will use the Camembert base model, but you are a free to use any model below. From my experience, Camembert was the best, with small training (~50% of F2 on first three epochs when finetuning)\n\n\nCode\nmodels = {\n    'bert': \"bert-base-uncased\",\n    'gpt': \"distilgpt2\",\n    'flau': \"flaubert/flaubert_base_uncased\",\n    'cmb': \"cmarkea/distilcamembert-base\",\n}\n\n\n\n\nZero-shot predictions\nWe will use a subset of the validation set to see how well the model perform with fine tuning\n\n\nCode\nX_valid_sample, X_valid, y_valid_sample, y_valid = train_test_split(test['message'], test['target'], test_size=0.95, random_state=42)\nX_valid_sample.shape, X_valid.shape, y_valid_sample.shape, y_valid.shape\n\n\n((9357,), (177783,), (9357,), (177783,))\n\n\n\n\nCode\n# Step 1: Install the necessary libraries (uncomment if not already installed)\n# !pip install transformers torch pandas tqdm scikit-learn\n\n# Step 2: Import Libraries\nimport pandas as pd\nfrom tqdm import tqdm\nfrom transformers import pipeline\nfrom sklearn.metrics import recall_score\n\n# Step 3: Load the zero-shot classification pipeline with CamemBERT\nclassifier = pipeline(\"zero-shot-classification\", model=\"camembert-base\")\n\n# Step 4: Load Your Dataset\n# For example, create a simple DataFrame with a 'target' column\ndata = {\n    \"text\": X_valid_sample[:1000],\n    \"target\": y_valid_sample[:1000]\n}\ndf = pd.DataFrame(data)\n\n# Define the binary candidate labels\ncandidate_labels = [\"positif\", \"négatif\"]\n\n# Step 5: Apply Zero-Shot Classification to Each Entry in the Dataset\ndef classify_text(text):\n    result = classifier(text, candidate_labels)\n    return result['labels'][0], result['scores'][0]  # Get the top label and its score\n\n# Apply classification with progress tracking\ntqdm.pandas()\n\ndf[['predicted_label', 'confidence_score']] = df['text'].progress_apply(lambda x: classify_text(x)).apply(pd.Series)\n\n# Step 6: Compute Metrics\n# Map target and predicted labels to binary values\nlabel_mapping = {\"positif\": 1, \"négatif\": 0}\ndf['target_binary'] = df['target']\ndf['predicted_binary'] = df['predicted_label'].map(label_mapping)\n\n# Calculate True Positives (tp), False Negatives (fn), and False Positives (fp)\ntp = ((df['target_binary'] == 1) & (df['predicted_binary'] == 1)).sum()\nfn = ((df['target_binary'] == 1) & (df['predicted_binary'] == 0)).sum()\nfp = ((df['target_binary'] == 0) & (df['predicted_binary'] == 1)).sum()\n\n# Compute Recall\nrecall = recall_score(df['target_binary'], df['predicted_binary'])\n\n# Compute Custom Metric F2\nF2 = tp / (tp + fn + fp) if (tp + fn + fp) &gt; 0 else 0\n\n# Display the results\nprint(f\"Recall: {recall}\")\nprint(f\"F2: {F2}\")\n\n\nSome weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nFailed to determine 'entailment' label id from the label2id mapping in the model config. Setting to -1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\n100%|██████████| 1000/1000 [01:31&lt;00:00, 10.98it/s]\n/usr/local/lib/python3.10/dist-packages/sklearn/utils/multiclass.py:380: RuntimeWarning: invalid value encountered in cast\n  if xp.any(data != data.astype(int)):\n\n\nValueError: Input y_true contains NaN.\n\n\n\n\nCode\n# Compute Recall\nrecall = recall_score(df['target'], df['predicted_binary'])\n\n# Compute Custom Metric F2\nF2 = tp / (tp + fn + fp) if (tp + fn + fp) &gt; 0 else 0\n\n# Display the results\nprint(f\"Recall: {recall}\")\nprint(f\"F2: {F2}\")\n\n\nRecall: 0.986013986013986\nF2: 0\n\n\n\n\nCode\nhistory = {}\nBATCH_SIZE = 16\nLEARNING_RATE = 1e-4\nweight_decay = 1e-2\nEPOCHS = 10\ndata = {'X_train': [], 'y_train': [], 'X_test': [], 'y_test': []}\nmodel, tokz, train_loader, test_loader = get_loader(models['cmb'], data, bs=BATCH_SIZE, use_special_pad_token=True, num_workers=8)\nmodel.to(device)\n\nclear_output()\nstart_time = time.time()\n\nevaluate_model(tokz, model, (X_valid_sample, y_valid_sample), history, device, bs = BATCH_SIZE * 2, plot_train=False)\n\nend_time = time.time()\nexecution_time = end_time - start_time\nprint(\"Execution time:\", execution_time, \"seconds\")\n\n\n/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \nThe secret `HF_TOKEN` does not exist in your Colab secrets.\nTo authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\nYou will be able to reuse this secret in all of your notebooks.\nPlease note that authentication is recommended but still optional to access public models or datasets.\n  warnings.warn(\nSome weights of CamembertForSequenceClassification were not initialized from the model checkpoint at cmarkea/distilcamembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTest Metrics:\n  Eval Accuracy: 0.8714331516511703\n  Eval Precision: 0.0\n  Eval Recall: 0.0\n  Eval score: 0.0\nExecution time: 78.14037203788757 seconds\n\n\n\n\nFine tuning\n\n\nCode\nX_train, y_train = train['message'], train['target']\nX_train_sample, y_train_sample = equal_class_sampling(X_train, y_train, 6000)\n_, X_test_sample, _, y_test_sample = train_test_split(X_valid, y_valid, test_size=0.02, random_state=42)\nX_test_sample.shape\n\n\n(3556,)\n\n\n\n\nCode\nhistory = {}\nBATCH_SIZE = 16\nLEARNING_RATE = 1e-4\nweight_decay = 1e-2\nEPOCHS = 10\ndata = {'X_train': X_train_sample, 'y_train': y_train_sample, 'X_test': X_test_sample, 'y_test': y_test_sample}\nmodel, tokz, train_loader, test_loader = get_loader(models['cmb'], data, bs=BATCH_SIZE, use_special_pad_token=True, num_workers=8)\nmodel.to(device)\n\nstart_time = time.time()\ntrain_model(model, train_loader, test_loader, history, num_epochs=EPOCHS, lr=LEARNING_RATE, early_stopping_patience=2, weight_decay=weight_decay)\nend_time = time.time()\nexecution_time = end_time - start_time\n\nclear_output()\nprint(\"Execution time:\", execution_time, \"seconds\")\n\nstart_time = time.time()\nevaluate_model(tokz, model, (X_valid_sample, y_valid_sample), history, device, bs = BATCH_SIZE * 2, plot_train=True)\nend_time = time.time()\nexecution_time = end_time - start_time\nprint(\"Execution time:\", execution_time, \"seconds\")\n\n\nExecution time: 363.3319444656372 seconds\nTest Metrics:\n  Eval Accuracy: 0.6475366036122688\n  Eval Precision: 0.23312101910828026\n  Eval Recall: 0.7605985037406484\n  Eval F2: 21.7184903868977\nExecution time: 84.7105667591095 seconds\n\n\n\n\n\n\n\n\n\n\n\nCode\nX_train, y_train = train['message'], train['target']\nX_train_sample, y_train_sample = equal_class_sampling(X_train, y_train, 10000)\n_, X_test_sample, _, y_test_sample = train_test_split(X_valid, y_valid, test_size=0.02, random_state=42)\nX_test_sample.shape\n\n\n(3556,)\n\n\n\n\nCode\nhistory = {}\nBATCH_SIZE = 16\nLEARNING_RATE = 1e-4\nweight_decay = 1e-2\nEPOCHS = 10\ndata = {'X_train': X_train_sample, 'y_train': y_train_sample, 'X_test': X_test_sample, 'y_test': y_test_sample}\nmodel, tokz, train_loader, test_loader = get_loader(models['cmb'], data, bs=BATCH_SIZE, use_special_pad_token=True, num_workers=8)\nmodel.to(device)\n\nstart_time = time.time()\ntrain_model(model, train_loader, test_loader, history, num_epochs=EPOCHS, lr=LEARNING_RATE, early_stopping_patience=2, weight_decay=weight_decay)\nend_time = time.time()\nexecution_time = end_time - start_time\n\nclear_output()\nprint(\"Execution time:\", execution_time, \"seconds\")\n\nstart_time = time.time()\nevaluate_model(tokz, model, (X_valid_sample, y_valid_sample), history, device, bs = BATCH_SIZE * 2, plot_train=True)\nend_time = time.time()\nexecution_time = end_time - start_time\nprint(\"Execution time:\", execution_time, \"seconds\")\n\n\nExecution time: 1122.6102643013 seconds\nTest Metrics:\n  Eval Accuracy: 0.6856898578604254\n  Eval Precision: 0.25793871866295265\n  Eval Recall: 0.769742310889443\n  Eval F2: 23.946211533488494\nExecution time: 84.70709776878357 seconds\n\n\n\n\n\n\n\n\n\n\n\nCode\nX_train, y_train = train['message'], train['target']\nX_train_sample, y_train_sample = equal_class_sampling(X_train, y_train, 15000)\n_, X_test_sample, _, y_test_sample = train_test_split(X_valid, y_valid, test_size=0.02, random_state=42)\nX_test_sample.shape\n\n\n(3556,)\n\n\n\n\nCode\nhistory = {}\nBATCH_SIZE = 32\nLEARNING_RATE = 1e-4\nweight_decay = 1e-2\nEPOCHS = 10\ndata = {'X_train': X_train_sample, 'y_train': y_train_sample, 'X_test': X_test_sample, 'y_test': y_test_sample}\nmodel, tokz, train_loader, test_loader = get_loader(models['cmb'], data, bs=BATCH_SIZE, use_special_pad_token=True, num_workers=8)\nmodel.to(device)\n\nstart_time = time.time()\ntrain_model(model, train_loader, test_loader, history, num_epochs=EPOCHS, lr=LEARNING_RATE, early_stopping_patience=2, weight_decay=weight_decay)\nend_time = time.time()\nexecution_time = end_time - start_time\n\nclear_output()\nprint(\"Execution time:\", execution_time, \"seconds\")\n\nstart_time = time.time()\nevaluate_model(tokz, model, (X_valid_sample, y_valid_sample), history, device, bs = BATCH_SIZE * 2, plot_train=True)\nend_time = time.time()\nexecution_time = end_time - start_time\nprint(\"Execution time:\", execution_time, \"seconds\")\n\n\nExecution time: 1914.5363965034485 seconds\nTest Metrics:\n  Eval Accuracy: 0.7079192048733568\n  Eval Precision: 0.26705237515225333\n  Eval Recall: 0.7290108063175395\n  Eval F2: 24.293628808864266\nExecution time: 85.33442664146423 seconds"
  },
  {
    "objectID": "posts/predicting_comment_reply_llm.html#sides",
    "href": "posts/predicting_comment_reply_llm.html#sides",
    "title": "Predicting Reply under Comment with LLM",
    "section": "Sides",
    "text": "Sides\n\n\nCode\n# Defining some key variables that will be used later on in the training\nBATCH_SIZE = 40\nEPOCHS = 10\nLEARNING_RATE = 1e-5\n\n# features = [col for col in train.columns if col not in ['id', 'target', 'message', 'topic']]\n# X_train, X_valid, y_train, y_valid = train_test_split(train['message'], train['target'], test_size=0.8, random_state=42)\n# X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.3, random_state=42)\n\n# X_train_sample, y_train_sample = equal_class_sampling(X_train, y_train, 6000)\n# X_test_sample, y_test_sample = equal_class_sampling(X_test, y_test, 2000)\n\n# X_train, X_valid, y_train, y_valid = train_test_split(train['message'], train['target'], test_size=0.1, random_state=42)\n# X_train, X_test, y_train, y_test = train_test_split(X_valid, y_valid, test_size=0.16, random_state=42)\n# X_train_sample, X_valid_sample, y_train_sample, y_valid_sample = train_test_split(X_test, y_test, test_size=0.3, random_state=42)\n# X_train_sample, X_test_sample, y_train_sample, y_test_sample = train_test_split(X_train_sample, y_train_sample, test_size=0.3, random_state=42)\n\n\n\n\nCode\nX_sample = train.sample(2000, replace=False, random_state=42)\nX_valid_sample, y_valid_sample = X_sample['message'], X_sample['target']\nX_train, y_train = train['message'], train['target']\nX_train_sample, y_train_sample = equal_class_sampling(X_train, y_train, 6000)\nX_test_sample, y_test_sample = equal_class_sampling(X_train, y_train, 2000)\n\n\n/tmp/ipykernel_34/545163474.py:6: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  sampled_elements = grouped.apply(lambda x: x.sample(min(num_samples_per_class, len(x))))\n/tmp/ipykernel_34/545163474.py:6: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  sampled_elements = grouped.apply(lambda x: x.sample(min(num_samples_per_class, len(x))))\n\n\n\n\nCode\nhistory = {}\nBATCH_SIZE = 16\nLEARNING_RATE = 1e-5\nEPOCHS = 10\ndata = {'X_train': X_train_sample, 'y_train': y_train_sample, 'X_test': X_test_sample, 'y_test': y_test_sample}\nmodel, tokz, train_loader, test_loader = get_loader(models['cmb'], data, bs=BATCH_SIZE, use_special_pad_token=True)\n# train_model(model, train_loader, test_loader, history, num_epochs=EPOCHS, lr=LEARNING_RATE)\n# clear_output()\nmodel.to(device)\nevaluate_model(tokz, model, (X_valid_sample, y_valid_sample), history, device, bs = 16, plot_train=False)\n\n\nSome weights of CamembertForSequenceClassification were not initialized from the model checkpoint at cmarkea/distilcamembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n\n\nTest Metrics:\n  Eval Accuracy: 0.874\n  Eval Precision: 0.0\n  Eval Recall: 0.0\n  Eval score: 0.0\n\n\n\n\nCode\nhistory = {}\nBATCH_SIZE = 16\nLEARNING_RATE = 1e-5\nEPOCHS = 10\ndata = {'X_train': X_train_sample, 'y_train': y_train_sample, 'X_test': X_test_sample, 'y_test': y_test_sample}\nmodel, tokz, train_loader, test_loader = get_loader(models['bert'], data, bs=BATCH_SIZE, use_special_pad_token=True)\n# train_model(model, train_loader, test_loader, history, num_epochs=EPOCHS, lr=LEARNING_RATE)\n# clear_output()\nmodel.to(device)\nevaluate_model(tokz, model, (X_valid_sample, y_valid_sample), history, device, bs = 16, plot_train=False)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n\n\nTest Metrics:\n  Eval Accuracy: 0.874\n  Eval Precision: 0.0\n  Eval Recall: 0.0\n  Eval score: 0.0\n\n\n\n\nCode\nhistory = {}\nBATCH_SIZE = 16\nLEARNING_RATE = 1e-5\nEPOCHS = 10\ndata = {'X_train': X_train_sample, 'y_train': y_train_sample, 'X_test': X_test_sample, 'y_test': y_test_sample}\nmodel, tokz, train_loader, test_loader = get_loader(models['flau'], data, bs=BATCH_SIZE, use_special_pad_token=True)\n# train_model(model, train_loader, test_loader, history, num_epochs=EPOCHS, lr=LEARNING_RATE)\n# clear_output()\nmodel.to(device)\nevaluate_model(tokz, model, (X_valid_sample, y_valid_sample), history, device, bs = 16, plot_train=False)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\nSome weights of FlaubertForSequenceClassification were not initialized from the model checkpoint at flaubert/flaubert_base_uncased and are newly initialized: ['sequence_summary.summary.bias', 'sequence_summary.summary.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n\n\nTest Metrics:\n  Eval Accuracy: 0.596\n  Eval Precision: 0.12021857923497267\n  Eval Recall: 0.3492063492063492\n  Eval score: 9.821428571428571\n\n\n\n\nCode\ntrain_sample = train.sample(5000, replace=False, random_state=42)\nX_train_sample, X_test_sample, y_train_sample, y_test_sample = train_test_split(train_sample['message'], train_sample['target'], test_size=0.3, random_state=42)\ntest_sample = test.sample(4000, replace=False, random_state=42)\nX_valid_sample, y_valid_sample = test_sample['message'], test_sample['target']\n\n\n\n\nCode\nhistory = {}\nBATCH_SIZE = 16\nLEARNING_RATE = 1e-6\nweight_decay = 1e-2\nEPOCHS = 40\ndata = {'X_train': X_train_sample, 'y_train': y_train_sample, 'X_test': X_test_sample, 'y_test': y_test_sample}\nmodel, tokz, train_loader, test_loader = get_loader(models['flau'], data, bs=BATCH_SIZE, use_special_pad_token=True)\ntrain_model(model, train_loader, test_loader, history, num_epochs=EPOCHS, lr=LEARNING_RATE, early_stopping_patience=3, weight_decay=weight_decay)\nclear_output()\n# model.to(device)\nevaluate_model(tokz, model, (X_valid_sample, y_valid_sample), history, device, bs = 16, plot_train=True)\n\n\n\n\n\n\n\n\n\nTest Metrics:\n  Eval Accuracy: 0.82175\n  Eval Precision: 0.28870292887029286\n  Eval Recall: 0.2700587084148728\n  Eval score: 16.216216216216218\n\n\n\n\nCode\nhistory = {}\nBATCH_SIZE = 16\nLEARNING_RATE = 1e-6\nweight_decay = 1e-2\nEPOCHS = 10\ndata = {'X_train': X_train_sample, 'y_train': y_train_sample, 'X_test': X_test_sample, 'y_test': y_test_sample}\nmodel, tokz, train_loader, test_loader = get_loader(models['flau'], data, bs=BATCH_SIZE, use_special_pad_token=True)\ntrain_model(model, train_loader, test_loader, history, num_epochs=EPOCHS, lr=LEARNING_RATE, early_stopping_patience=3, weight_decay=weight_decay)\nclear_output()\n# model.to(device)\nevaluate_model(tokz, model, (X_valid_sample, y_valid_sample), history, device, bs = 16, plot_train=True)\n\n\n\n\n\n\n\n\n\nTest Metrics:\n  Eval Accuracy: 0.79275\n  Eval Precision: 0.24271844660194175\n  Eval Recall: 0.29354207436399216\n  Eval score: 15.321756894790603\n\n\n\n\nCode\nhistory = {}\nBATCH_SIZE = 16\nLEARNING_RATE = 1e-4\nweight_decay = 1e-2\nEPOCHS = 10\ndata = {'X_train': X_train_sample, 'y_train': y_train_sample, 'X_test': X_test_sample, 'y_test': y_test_sample}\nmodel, tokz, train_loader, test_loader = get_loader(models['cmb'], data, bs=BATCH_SIZE, use_special_pad_token=True)\ntrain_model(model, train_loader, test_loader, history, num_epochs=EPOCHS, lr=LEARNING_RATE, early_stopping_patience=3, weight_decay=weight_decay)\nclear_output()\n# model.to(device)\nevaluate_model(tokz, model, (X_valid_sample, y_valid_sample), history, device, bs = 16, plot_train=True)\n\n\n\n\n\n\n\n\n\nTest Metrics:\n  Eval Accuracy: 0.82\n  Eval Precision: 0.3219761499148211\n  Eval Recall: 0.3698630136986301\n  Eval score: 20.792079207920793\n\n\n\n\nCode\nhistory = {}\nBATCH_SIZE = 16\nLEARNING_RATE = 1e-5\nweight_decay = 1e-2\nEPOCHS = 10\ndata = {'X_train': X_train_sample, 'y_train': y_train_sample, 'X_test': X_test_sample, 'y_test': y_test_sample}\nmodel, tokz, train_loader, test_loader = get_loader(models['cmb'], data, bs=BATCH_SIZE, use_special_pad_token=True)\ntrain_model(model, train_loader, test_loader, history, num_epochs=EPOCHS, lr=LEARNING_RATE, early_stopping_patience=3, weight_decay=weight_decay)\nclear_output()\n# model.to(device)\nevaluate_model(tokz, model, (X_valid_sample, y_valid_sample), history, device, bs = 16, plot_train=True)\n\n\n\n\n\n\n\n\n\nTest Metrics:\n  Eval Accuracy: 0.81075\n  Eval Precision: 0.29152542372881357\n  Eval Recall: 0.33659491193737767\n  Eval score: 18.51453175457481\n\n\n\n\nCode\nhistory = {}\nBATCH_SIZE = 16\nLEARNING_RATE = 1e-5\nweight_decay = 1e-2\nEPOCHS = 10\ndata = {'X_train': X_train_sample, 'y_train': y_train_sample, 'X_test': X_test_sample, 'y_test': y_test_sample}\nmodel, tokz, train_loader, test_loader = get_loader(models['cmb'], data, bs=BATCH_SIZE, use_special_pad_token=True)\ntrain_model(model, train_loader, test_loader, history, num_epochs=EPOCHS, lr=LEARNING_RATE, early_stopping_patience=3, weight_decay=weight_decay)\nclear_output()\n# model.to(device)\nevaluate_model(tokz, model, (X_valid_sample, y_valid_sample), history, device, bs = 16, plot_train=True)\n\n\n\n\n\n\n\n\n\nTest Metrics:\n  Eval Accuracy: 0.85375\n  Eval Precision: 0.3072916666666667\n  Eval Recall: 0.11545988258317025\n  Eval score: 9.161490683229815\n\n\n\n\nCode\nhistory = {}\nBATCH_SIZE = 16\nLEARNING_RATE = 1e-5\nweight_decay = 1e-2\nEPOCHS = 10\ndata = {'X_train': X_train_sample, 'y_train': y_train_sample, 'X_test': X_test_sample, 'y_test': y_test_sample}\nmodel, tokz, train_loader, test_loader = get_loader(models['cmb'], data, bs=BATCH_SIZE, use_special_pad_token=True)\ntrain_model(model, train_loader, test_loader, history, num_epochs=EPOCHS, lr=LEARNING_RATE, early_stopping_patience=3, weight_decay=weight_decay)\nclear_output()\n# model.to(device)\nevaluate_model(tokz, model, (X_valid_sample, y_valid_sample), history, device, bs = 16, plot_train=True)\n\n\n\n\n\n\n\n\n\nTest Metrics:\n  Eval Accuracy: 0.817\n  Eval Precision: 0.29345794392523367\n  Eval Recall: 0.30724070450097846\n  Eval score: 17.66029246344207\n\n\nConclusion: use here a sample of training data, then model can improve depend on dataset, and lr with weigth decay"
  },
  {
    "objectID": "posts/predicting_comment_reply_llm.html#fine-tunning-of-cmb",
    "href": "posts/predicting_comment_reply_llm.html#fine-tunning-of-cmb",
    "title": "Predicting Reply under Comment with LLM",
    "section": "Fine tunning of Cmb",
    "text": "Fine tunning of Cmb\n\n\nCode\nX_train, y_train = train['message'], train['target']\nX_train_sample, y_train_sample = equal_class_sampling(X_train, y_train, 10000)\nX_train_sample, X_test_sample, y_train_sample, y_test_sample = train_test_split(X_train_sample, y_train_sample, test_size=0.2, random_state=42)\nX_valid_sample, y_valid_sample = test['message'], test['target']\n\n\n/tmp/ipykernel_34/545163474.py:6: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  sampled_elements = grouped.apply(lambda x: x.sample(min(num_samples_per_class, len(x))))\n\n\n\n\nCode\nhistory = {}\nBATCH_SIZE = 16\nLEARNING_RATE = 1e-4\nweight_decay = 1e-2\nEPOCHS = 10\ndata = {'X_train': X_train_sample, 'y_train': y_train_sample, 'X_test': X_test_sample, 'y_test': y_test_sample}\nmodel, tokz, train_loader, test_loader = get_loader(models['cmb'], data, bs=BATCH_SIZE, use_special_pad_token=True, num_workers=0)\nstart_time = time.time()\n\ntrain_model(model, train_loader, test_loader, history, num_epochs=EPOCHS, lr=LEARNING_RATE, early_stopping_patience=2, weight_decay=weight_decay)\n\nend_time = time.time()\nexecution_time = end_time - start_time\n\nclear_output()\nprint(\"Execution time:\", execution_time, \"seconds\")\n# model.to(device)\n\nstart_time = time.time()\n\nevaluate_model(tokz, model, (X_valid_sample, y_valid_sample), history, device, bs = 16, plot_train=True)\n\nend_time = time.time()\nexecution_time = end_time - start_time\nprint(\"Execution time:\", execution_time, \"seconds\")\n\n\nExecution time: 700.7525315284729 seconds\nTest Metrics:\n  Eval Accuracy: 0.7053703109971144\n  Eval Precision: 0.24839120789212832\n  Eval Recall: 0.6818260343785091\n  Eval score: 22.25903784332525\nExecution time: 1724.11274600029 seconds\n\n\n\n\n\n\n\n\n\n\n\nCode\nhistory = {}\nBATCH_SIZE = 16\nLEARNING_RATE = 1e-4\nweight_decay = 1e-2\nEPOCHS = 10\ndata = {'X_train': X_train_sample, 'y_train': y_train_sample, 'X_test': X_test_sample, 'y_test': y_test_sample}\nmodel, tokz, train_loader, test_loader = get_loader(models['cmb'], data, bs=BATCH_SIZE, use_special_pad_token=True, num_workers=2)\nstart_time = time.time()\n\ntrain_model(model, train_loader, test_loader, history, num_epochs=EPOCHS, lr=LEARNING_RATE, early_stopping_patience=2, weight_decay=weight_decay)\n\nend_time = time.time()\nexecution_time = end_time - start_time\n\nclear_output()\nprint(\"Execution time:\", execution_time, \"seconds\")\n# model.to(device)\n\nstart_time = time.time()\n\nevaluate_model(tokz, model, (X_valid_sample, y_valid_sample), history, device, bs = 16, plot_train=True)\n\nend_time = time.time()\nexecution_time = end_time - start_time\nprint(\"Execution time:\", execution_time, \"seconds\")\n\n\nExecution time: 691.7326118946075 seconds\nTest Metrics:\n  Eval Accuracy: 0.7420487335684515\n  Eval Precision: 0.2642692242722273\n  Eval Recall: 0.6081022717457026\n  Eval score: 22.58111077253701\nExecution time: 1725.678540468216 seconds\n\n\n\n\n\n\n\n\n\n\n\nCode\nhistory = {}\nBATCH_SIZE = 16\nLEARNING_RATE = 1e-4\nweight_decay = 1e-2\nEPOCHS = 10\ndata = {'X_train': X_train_sample, 'y_train': y_train_sample, 'X_test': X_test_sample, 'y_test': y_test_sample}\nmodel, tokz, train_loader, test_loader = get_loader(models['cmb'], data, bs=BATCH_SIZE, use_special_pad_token=True, num_workers=2)\nstart_time = time.time()\n\ntrain_model(model, train_loader, test_loader, history, num_epochs=EPOCHS, lr=LEARNING_RATE, early_stopping_patience=2, weight_decay=weight_decay)\n\nend_time = time.time()\nexecution_time = end_time - start_time\n\nclear_output()\nprint(\"Execution time:\", execution_time, \"seconds\")\n# model.to(device)\n\n# start_time = time.time()\n\n# evaluate_model(tokz, model, (X_valid_sample, y_valid_sample), history, device, bs = 16, plot_train=True)\n\n# end_time = time.time()\n# execution_time = end_time - start_time\n# print(\"Execution time:\", execution_time, \"seconds\")\n\n\nExecution time: 687.4640731811523 seconds\n\n\n\n\nCode\nhistory = {}\nBATCH_SIZE = 16\nLEARNING_RATE = 1e-4\nweight_decay = 1e-2\nEPOCHS = 10\ndata = {'X_train': X_train_sample, 'y_train': y_train_sample, 'X_test': X_test_sample, 'y_test': y_test_sample}\nmodel, tokz, train_loader, test_loader = get_loader(models['cmb'], data, bs=BATCH_SIZE, use_special_pad_token=True, num_workers=4)\nstart_time = time.time()\n\ntrain_model(model, train_loader, test_loader, history, num_epochs=EPOCHS, lr=LEARNING_RATE, early_stopping_patience=2, weight_decay=weight_decay)\n\nend_time = time.time()\nexecution_time = end_time - start_time\n\nclear_output()\nprint(\"Execution time:\", execution_time, \"seconds\")\n# model.to(device)\n\n# start_time = time.time()\n\n# evaluate_model(tokz, model, (X_valid_sample, y_valid_sample), history, device, bs = 16, plot_train=True)\n\n# end_time = time.time()\n# execution_time = end_time - start_time\n# print(\"Execution time:\", execution_time, \"seconds\")\n\n\nExecution time: 688.4917013645172 seconds\n\n\n\n\nCode\n\n\n\n2\n\n\n\n\nCode\ntest_sample = test.sample(10000, replace=False, random_state=42)\nX_valid_sample, y_valid_sample = test_sample['message'], test_sample['target']\nevaluate_model(tokz, model, (X_valid_sample, y_valid_sample), history, device, bs = 32, plot_train=True)\n\n\n\n\n\n\n\n\n\nTest Metrics:\n  Eval Accuracy: 0.6967\n  Eval Precision: 0.23997623997623999\n  Eval Recall: 0.6302652106084243\n  Eval score: 21.036188492580056\n\n\n\n\nCode\nX_train_sample, X_test_sample, y_train_sample, y_test_sample = train_test_split(test['message'], test['target'], test_size=0.1, random_state=42)\nX_train_sample, y_train_sample = equal_class_sampling(X_train_sample, y_train_sample, 10000)\nX_valid_sample, X_test_sample, y_valid_sample, y_test_sample = train_test_split(X_test_sample, y_test_sample, test_size=0.2, random_state=42)\n\n\n/tmp/ipykernel_34/545163474.py:6: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  sampled_elements = grouped.apply(lambda x: x.sample(min(num_samples_per_class, len(x))))\n\n\n\n\nCode\ny_test_sample.shape, y_valid_sample.shape\n\n\n((3743,), (14971,))\n\n\n\n\nCode\ntrain_dataset = CommentDataset(X_train_sample.to_numpy(), y_train_sample.astype(int).to_numpy(), tokz)\ntest_dataset = CommentDataset(X_test_sample.to_numpy(), y_test_sample.astype(int).to_numpy(), tokz)\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=16, shuffle=True)\n\n\n\n\nCode\ntorch.save(model.state_dict(), 'cmb_1e-4_21.pth')\n\n\n\n\nCode\nhistory = {}\nBATCH_SIZE = 16\nLEARNING_RATE = 1e-4\nweight_decay = 1e-2\nEPOCHS = 10\n# data = {'X_train': X_train_sample, 'y_train': y_train_sample, 'X_test': X_test_sample, 'y_test': y_test_sample}\n# model, tokz, train_loader, test_loader = get_loader(models['cmb'], data, bs=BATCH_SIZE, use_special_pad_token=True)\ntrain_model(model, train_loader, test_loader, history, num_epochs=EPOCHS, lr=LEARNING_RATE, early_stopping_patience=2, weight_decay=weight_decay)\nclear_output()\n# model.to(device)\nevaluate_model(tokz, model, (X_valid_sample, y_valid_sample), history, device, bs = 16, plot_train=True)\n\n\n\n\n\n\n\n\n\nTest Metrics:\n  Eval Accuracy: 0.6584730478925923\n  Eval Precision: 0.22983870967741934\n  Eval Recall: 0.7211386399578281\n  Eval score: 21.107853726276808\n\n\n\n\nCode\nfrom collections import Counter\n\ndef predic(tokz, model, valid_data, device, bs = 16):\n    model.eval()\n    test_preds = []\n\n    valid_dataset = CommentDataset(valid_data[0].to_numpy(), valid_data[1].astype(int).to_numpy(), tokz)\n    test_dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=bs, shuffle=True)\n\n    with torch.no_grad():\n        for _, batch in enumerate(tqdm(test_dataloader, desc=f'Inference on batch ')):\n#         for batch in test_dataloader:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            token_type_ids = batch['token_type_ids'].to(device)\n\n            outputs = model(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n            logits = outputs.logits.squeeze(1)\n\n            test_preds.extend((logits &gt; 0.5).int().tolist())\n\n    print(sorted(Counter(test_preds).items()))\n\n    return test_preds\n\n\n\n\nCode\ntorch.save(model.state_dict(), 'cmb_1e-4_21_2.pth')\n\n\n\n\nCode\nX_train_sample, X_test_sample, y_train_sample, y_test_sample = train_test_split(test['message'], test['target'], test_size=0.1, random_state=42)\nX_train_sample, y_train_sample = equal_class_sampling(X_train_sample, y_train_sample, 10000)\nX_valid_sample, X_test_sample, y_valid_sample, y_test_sample = train_test_split(X_test_sample, y_test_sample, test_size=0.2, random_state=42)\ndata = {'X_train': X_train_sample, 'y_train': y_train_sample, 'X_test': X_test_sample, 'y_test': y_test_sample}\nmodel, tokz, train_loader, test_loader = get_loader(models['cmb'], data, bs=16, use_special_pad_token=True)\nmodel.load_state_dict(torch.load('/kaggle/input/camembert-fine-tuned-on-predicting-comment-reply/pytorch/cmb_21_2/1/cmb_1e-4_21_2.pth', map_location=torch.device('cpu')))\n\n\n/tmp/ipykernel_33/545163474.py:6: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  sampled_elements = grouped.apply(lambda x: x.sample(min(num_samples_per_class, len(x))))\nSome weights of CamembertForSequenceClassification were not initialized from the model checkpoint at cmarkea/distilcamembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;All keys matched successfully&gt;\n\n\n\n\nCode\nvalid.shape\n\n\n(107470, 61)\n\n\n\n\nCode\nvalid['pred'] = 0\ny = valid['pred']\nx = valid['message']\npreds = predic(tokz, model, (x, y), device, bs = 32)\n\n\nInference on batch :  61%|██████    | 2053/3359 [11:46:12&lt;7:28:20, 20.60s/it]\n\n\n\n\nCode\npreds\n\n\n\n\nCode\nvalid['pred'] = preds\nvalid.to_csv(\"cmb_21_pred.csv\")\nvalid[pred == 1]['id'].to_csv(\"cmb_21_pred_id.csv\")\nvalid[pred == 1]['id'].to_csv(\"cmb_21_pred_id.txt\", sep='\\n', index=False)"
  }
]